{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3a8f0901"
      },
      "source": [
        "<p>\n",
        "  <a href=\"https://visitorbadge.io/status?path=colab-1DkhCfMOAJ51B1rXFtm52lrzBqqPNtbVk\">\n",
        "    <img\n",
        "      src=\"https://api.visitorbadge.io/api/visitors?path=colab-1DkhCfMOAJ51B1rXFtm52lrzBqqPNtbVk&label=Visitors&labelColor=%232e3440&countColor=%2337d67a&style=flat&labelStyle=none\"\n",
        "      width=\"157\"\n",
        "      alt=\"Visitors\"\n",
        "    />\n",
        "  </a>\n",
        "  &nbsp;&nbsp;\n",
        "  <a href=\"https://github.com/thaakeno/ComfyUI-Colab-Notebook\">\n",
        "    <img\n",
        "      src=\"https://img.shields.io/badge/GitHub-181717?logo=github&logoColor=white&style=flat\"\n",
        "      width=\"135\"\n",
        "      alt=\"GitHub\"\n",
        "    />\n",
        "  </a>\n",
        "  &nbsp;&nbsp;\n",
        "  <a href=\"https://colab.research.google.com/drive/1DkhCfMOAJ51B1rXFtm52lrzBqqPNtbVk?usp=sharing&authuser=1\">\n",
        "    <img\n",
        "      src=\"https://img.shields.io/badge/-Colab-FFA500?logo=googlecolab&logoColor=white&style=flat\"\n",
        "      width=\"120\"\n",
        "      alt=\"Colab\"\n",
        "    />\n",
        "  </a>\n",
        "</p>\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# **Make it more comfy.**\n",
        "A Colab Notebook For Using ComfyUI directly on Google Colab.\n",
        "\n",
        "\n",
        "# <img src=\"https://canada1.discourse-cdn.com/flex009/uploads/comfyui1/original/1X/25e008c94747ee168196fecdcc8a5f11fc04c9ad.png\" width=\"500\">\n",
        "\n",
        "\n",
        "# 🚀 ComfyUI on Google Colab: Beginner-Friendly & Flexible Setup\n",
        "\n",
        "\n",
        "\n",
        "Welcome to this guide for running **ComfyUI on Google Colab**. This version introduces a flexible storage option to choose between saving everything to Google Drive or keeping large model files in the temporary Colab storage to save Drive space aswell.\n",
        "\n",
        ">⚡Made by [thaakeno](https://x.com/thaakeno) | Modified for flexible storage\n",
        "---\n",
        "\n",
        "## 💾 Storage Options Explained\n",
        "\n",
        "A new **`SAVE_TO_GDRIVE`** toggle has been added to the configuration. Here’s how it works:\n",
        "\n",
        "**✅ When `SAVE_TO_GDRIVE` is CHECKED (True):**\n",
        "*   **Everything** is saved to your Google Drive in the specified `GDRIVE_BASE` folder.\n",
        "*   This includes `checkpoints`, `loras`, `vae`, `clip`, `custom_nodes`, `input`, and `output` folders.\n",
        "*   **Benefit:** Your entire setup is persistent. You won't need to re-download models every time you start the Colab.\n",
        "\n",
        "**❌ When `SAVE_TO_GDRIVE` is UNCHECKED (False):**\n",
        "*   **Only essential data and custom nodes** are saved to Google Drive to ensure your work and configurations are safe.\n",
        "*   **Saved to Google Drive:** `input`, `output`, `temp`, `user`, and `custom_nodes` folders.\n",
        "*   **Saved to Colab's temporary storage:** All model files, including `checkpoints`, `loras`, `vae`, and `clip`.\n",
        "*   **Benefit:** Saves a significant amount of Google Drive space. The tradeoff is that you will need to re-download all models each time you run the notebook.\n",
        "\n",
        "---\n",
        "\n",
        "## ⚙️ Runtime Requirements\n",
        "\n",
        "Before getting started, **make sure you're using a GPU runtime**:\n",
        "\n",
        "1. Click `Runtime` > `Change runtime type`\n",
        "2. Set \"Hardware accelerator\" to **T4 GPU** or **A100 GPU**\n",
        "\n",
        "---\n",
        "\n",
        "## ✨ Configuration & Setup\n",
        "\n",
        "Let’s configure your setup. Modify the variables below. You can use Colab's Secrets for your API keys or paste them directly.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "fc6e9240"
      },
      "outputs": [],
      "source": [
        "# @title ⚙️ Enhanced ComfyUI User Configuration\n",
        "# @markdown This configuration sets up ComfyUI with various integrations and model sources.\n",
        "\n",
        "# @markdown ---\n",
        "# @markdown ## 💾 **Google Drive Integration**\n",
        "# @markdown **Save to Google Drive:** Check this box to save ALL models, nodes, and data to Google Drive.\n",
        "# @markdown Uncheck to save only essential data and lightweight models to Google Drive, while heavy models (checkpoints, LoRAs) are saved to temporary Colab storage.\n",
        "SAVE_TO_GDRIVE = False  # @param {type:\"boolean\"}\n",
        "\n",
        "# @markdown **Google Drive Base Folder:** Define the base folder in your Google Drive where ComfyUI data will be stored.\n",
        "# @markdown Leave empty to use the root directory, or specify a folder like \"ComfyUI\" or \"AI/ComfyUI\"\n",
        "GDRIVE_BASE = '/content/drive/MyDrive/ComfyUI' # @param {type:\"string\"}\n",
        "\n",
        "# @markdown ---\n",
        "# @markdown ## 🤗 **Hugging Face Integration**\n",
        "# @markdown **Required for FLUX and other gated models**\n",
        "# @markdown\n",
        "# @markdown 🔗 **Get your token here:** https://huggingface.co/settings/tokens\n",
        "# @markdown\n",
        "# @markdown ℹ️ **Instructions:**\n",
        "# @markdown 1. Visit the link above and log in to Hugging Face\n",
        "# @markdown 2. Click \"New token\"\n",
        "# @markdown 3. Choose \"Read\" access type\n",
        "# @markdown 4. Copy and paste the token below\n",
        "HF_TOKEN = \"\" # @param {type:\"string\"}\n",
        "\n",
        "# @markdown ---\n",
        "# @markdown ## 🎨 **Civitai Integration**\n",
        "# @markdown **For downloading community models, LoRAs, and checkpoints**\n",
        "# @markdown\n",
        "# @markdown 🔗 **Get your API key here:** https://civitai.com/user/account\n",
        "# @markdown\n",
        "# @markdown ℹ️ **Instructions:**\n",
        "# @markdown 1. Visit the link above and log in to Civitai\n",
        "# @markdown 2. Scroll down to \"API Keys\" section\n",
        "# @markdown 3. Click \"Add API key\"\n",
        "# @markdown 4. Copy and paste the key below\n",
        "CIVITAI_API_KEY = \"\" # @param {type:\"string\"}\n",
        "\n",
        "# @markdown ---\n",
        "# @markdown ## 🌐 **Ngrok Integration**\n",
        "# @markdown **Create public URLs to access ComfyUI from anywhere**\n",
        "# @markdown\n",
        "# @markdown 🔗 **Get your authtoken here:** https://dashboard.ngrok.com/get-started/your-authtoken\n",
        "# @markdown\n",
        "# @markdown ℹ️ **Instructions:**\n",
        "# @markdown 1. Visit the link above and sign up/log in to Ngrok\n",
        "# @markdown 2. Your authtoken will be displayed on the page\n",
        "# @markdown 3. Copy and paste the authtoken below\n",
        "# @markdown\n",
        "\n",
        "NGROK_AUTHTOKEN = \"\" # @param {type:\"string\"}\n",
        "\n",
        "# @markdown ---\n",
        "# @markdown ## 🔄 **Model Management**\n",
        "# @markdown **Force Model Refresh:** Set to `True` to force re-downloading all models, even if they already exist.\n",
        "\n",
        "# @markdown ⚠️ **Warning:** This will increase download time and data usage.\n",
        "FORCE_MODEL_REFRESH = False # @param {type:\"boolean\"}\n",
        "# @markdown Don't forget to run this cell to save ur configuration.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06137671"
      },
      "source": [
        "---\n",
        "\n",
        "## 📦 Install Dependencies & Setup ComfyUI\n",
        "\n",
        "Now, let's install the necessary system dependencies and set up the ComfyUI environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "0b48fa12"
      },
      "outputs": [],
      "source": [
        "# @title ⚙️ Install Dependencies & Setup ComfyUI (with Progress & Timings)\n",
        "# @markdown This cell installs system libraries, clones the ComfyUI repository to a stable version, and installs dependencies.\n",
        "# @markdown It provides progress bars for downloads and reports the time taken for each step.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "# --- Helper function to run commands that should be silent ---\n",
        "def run_quiet(cmd):\n",
        "    \"\"\"Runs a shell command and hides the output.\"\"\"\n",
        "    os.system(f\"{cmd} > /dev/null 2>&1\")\n",
        "\n",
        "# --- Start of the setup process ---\n",
        "display(Markdown(\"### 🚀 **Starting ComfyUI Environment Setup**\"))\n",
        "total_start_time = time.time()\n",
        "\n",
        "# --- Step 1: System Dependencies ---\n",
        "print(\"\\n[1/4] 📦 Installing system dependencies (apt)...\")\n",
        "step_start_time = time.time()\n",
        "run_quiet(\"apt -y update -qq\")\n",
        "run_quiet(\"apt -y install -qq libgl1-mesa-glx wget git\")\n",
        "duration = time.time() - step_start_time\n",
        "print(f\"✅ System dependencies ready. (Took {duration:.2f}s)\")\n",
        "\n",
        "# --- Step 2: Clone ComfyUI Repository ---\n",
        "print(\"\\n[2/4] 📂 Cloning ComfyUI repository...\")\n",
        "step_start_time = time.time()\n",
        "if not os.path.exists('/content/ComfyUI'):\n",
        "    # We use !git clone --progress to show the download bar\n",
        "    !git clone --progress https://github.com/comfyanonymous/ComfyUI.git\n",
        "else:\n",
        "    print(\"✅ Repository already exists, skipping clone.\")\n",
        "os.chdir('/content/ComfyUI')\n",
        "duration = time.time() - step_start_time\n",
        "print(f\"✅ Repository is ready. (Took {duration:.2f}s)\")\n",
        "\n",
        "# --- Step 3: Checkout Stable Version ---\n",
        "print(\"\\n[3/4] 🔄 Switching to stable version (v0.3.46)...\")\n",
        "step_start_time = time.time()\n",
        "# These git commands are fast and don't need progress bars, so we keep them quiet.\n",
        "run_quiet(\"git fetch\")\n",
        "run_quiet(\"git checkout v0.3.46\")\n",
        "duration = time.time() - step_start_time\n",
        "print(f\"✅ ComfyUI is now on the correct stable version. (Took {duration:.2f}s)\")\n",
        "\n",
        "# --- Step 4: Install Python Dependencies ---\n",
        "print(\"\\n[4/4] 🐍 Installing Python requirements (pip)...\")\n",
        "step_start_time = time.time()\n",
        "# Using !pip without the quiet flag (-q) will show the download progress for packages\n",
        "!{sys.executable} -m pip install -r requirements.txt\n",
        "duration = time.time() - step_start_time\n",
        "print(f\"✅ Python dependencies installed. (Took {duration:.2f}s)\")\n",
        "\n",
        "# --- Final Verification ---\n",
        "total_duration = time.time() - total_start_time\n",
        "display(Markdown(\"---\"))\n",
        "import torch\n",
        "if torch.cuda.is_available():\n",
        "    display(Markdown(f\"✅ **Setup Complete!** GPU detected: **{torch.cuda.get_device_name(0)}**\"))\n",
        "else:\n",
        "    display(Markdown(\"⚠️ **Warning:** No GPU detected. Running on CPU will be extremely slow.\"))\n",
        "\n",
        "display(Markdown(f\"⏱️ **Total setup time: {total_duration:.2f} seconds.**\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "940b79d4"
      },
      "source": [
        "---\n",
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/6/6a/Google_Drive_text_logo_grey.png/1200px-Google_Drive_text_logo_grey.png\" width=\"300\">\n",
        "\n",
        "\n",
        "\n",
        "## ☁️ Integrate with Google Drive & Configure Paths\n",
        "\n",
        "This section mounts your Google Drive, creates folders, and generates the `extra_model_paths.yaml` file to tell ComfyUI where to find everything, based on your `SAVE_TO_GDRIVE` setting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "fd2f290f"
      },
      "outputs": [],
      "source": [
        "# @title Mount Google Drive and Create Folders\n",
        "# @markdown This cell mounts your Google Drive and creates the necessary folder structure based on your `SAVE_TO_GDRIVE` setting.\n",
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "COMFYUI_PATH = '/content/ComfyUI'\n",
        "\n",
        "if SAVE_TO_GDRIVE:\n",
        "    print(\"💾 `SAVE_TO_GDRIVE` is ON. Creating full folder structure in Google Drive.\")\n",
        "    REQUIRED_FOLDERS = [\n",
        "        'models/checkpoints', 'models/loras', 'models/controlnet',\n",
        "        'models/vae', 'models/upscale_models', 'models/clip', 'models/unet',\n",
        "        'models/clip_vision', # Added clip_vision folder\n",
        "        'custom_nodes', 'input', 'output', 'temp', 'user'\n",
        "    ]\n",
        "    for folder in REQUIRED_FOLDERS:\n",
        "        os.makedirs(os.path.join(GDRIVE_BASE, folder), exist_ok=True)\n",
        "else:\n",
        "    print(\"☁️ `SAVE_TO_GDRIVE` is OFF. Creating minimal structure in GDrive and temporary folders in Colab.\")\n",
        "    # Folders to persist in Google Drive\n",
        "    GDRIVE_PERSIST_FOLDERS = ['custom_nodes', 'input', 'output', 'temp', 'user']\n",
        "    for folder in GDRIVE_PERSIST_FOLDERS:\n",
        "        os.makedirs(os.path.join(GDRIVE_BASE, folder), exist_ok=True)\n",
        "\n",
        "    # Folders to create in the temporary Colab runtime\n",
        "    LOCAL_TEMP_FOLDERS = [\n",
        "        'models/checkpoints', 'models/loras', 'models/controlnet',\n",
        "        'models/vae', 'models/upscale_models', 'models/clip', 'models/unet',\n",
        "        'models/clip_vision' # Added clip_vision folder\n",
        "    ]\n",
        "    for folder in LOCAL_TEMP_FOLDERS:\n",
        "        os.makedirs(os.path.join(COMFYUI_PATH, folder), exist_ok=True)\n",
        "\n",
        "print(\"✅ Directory structure is ready.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "fa446884"
      },
      "outputs": [],
      "source": [
        "# @title Configure ComfyUI Paths\n",
        "# @markdown This cell creates the `extra_model_paths.yaml` file. The paths are set dynamically based on your `SAVE_TO_GDRIVE` selection.\n",
        "\n",
        "import os\n",
        "import yaml # Import yaml library\n",
        "\n",
        "COMFYUI_PATH = '/content/ComfyUI'\n",
        "yaml_content = {}\n",
        "\n",
        "if SAVE_TO_GDRIVE:\n",
        "    print(\"💾 Pointing all ComfyUI paths to Google Drive.\")\n",
        "    yaml_content = {\n",
        "        \"gdrive_storage\": {\n",
        "            \"checkpoints\": f\"{GDRIVE_BASE}/models/checkpoints/\",\n",
        "            \"loras\": f\"{GDRIVE_BASE}/models/loras/\",\n",
        "            \"controlnet\": f\"{GDRIVE_BASE}/models/controlnet/\",\n",
        "            \"vae\": f\"{GDRIVE_BASE}/models/vae/\",\n",
        "            \"upscale_models\": f\"{GDRIVE_BASE}/models/upscale_models/\",\n",
        "            \"clip\": f\"{GDRIVE_BASE}/models/clip/\",\n",
        "            \"unet\": f\"{GDRIVE_BASE}/models/unet/\",\n",
        "            \"clip_vision\": f\"{GDRIVE_BASE}/models/clip_vision/\", # Added clip_vision path\n",
        "            \"custom_nodes\": f\"{GDRIVE_BASE}/custom_nodes/\",\n",
        "            \"input\": f\"{GDRIVE_BASE}/input/\",\n",
        "            \"output\": f\"{GDRIVE_BASE}/output/\",\n",
        "            \"temp\": f\"{GDRIVE_BASE}/temp/\",\n",
        "        }\n",
        "    }\n",
        "else:\n",
        "    print(\"☁️ Pointing essential paths to Google Drive and using local runtime for all models.\")\n",
        "    # Only paths for persistent data point to Google Drive. Models will use the default local paths.\n",
        "    yaml_content = {\n",
        "        \"gdrive_storage\": {\n",
        "            # All model paths (checkpoints, loras, vae, clip, etc.) are omitted.\n",
        "            # ComfyUI will use its default local directories inside /content/ComfyUI/models/.\n",
        "            \"clip_vision\": f\"{GDRIVE_BASE}/models/clip_vision/\", # Added clip_vision path\n",
        "            # These paths are set to Google Drive for persistence.\n",
        "            \"custom_nodes\": f\"{GDRIVE_BASE}/custom_nodes/\",\n",
        "            \"input\": f\"{GDRIVE_BASE}/input/\",\n",
        "            \"output\": f\"{GDRIVE_BASE}/output/\",\n",
        "            \"temp\": f\"{GDRIVE_BASE}/temp/\",\n",
        "        }\n",
        "    }\n",
        "\n",
        "with open(os.path.join(COMFYUI_PATH, \"extra_model_paths.yaml\"), \"w\") as f:\n",
        "    yaml.dump(yaml_content, f) # Use yaml.dump to write the content\n",
        "\n",
        "print(\"✅ ComfyUI path configuration complete.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7350ef2"
      },
      "source": [
        "---\n",
        "\n",
        "## ⬇️ Download Models from CIVITAI, HUGGINGFACE & MEGA\n",
        "\n",
        "Download essential models required for ComfyUI. This cell includes examples for downloading models from each site."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "92cbffb2"
      },
      "outputs": [],
      "source": [
        "# @title 📥 Universal Asset Downloader (Civitai, Hugging Face, MEGA)\n",
        "# @markdown Paste any URL from Civitai (model or image page), Hugging Face (repo or file), or a MEGA link. The script will automatically detect the source and download all associated assets to the correct folders.\n",
        "\n",
        "import os\n",
        "import re\n",
        "import requests\n",
        "from tqdm.notebook import tqdm\n",
        "from pathlib import Path\n",
        "from urllib.parse import urlparse\n",
        "import subprocess\n",
        "import shutil\n",
        "from typing import Optional, Dict, Any\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "# @markdown ---\n",
        "# @markdown **Asset URL(s):**\n",
        "# @markdown Paste one or more URLs from Civitai (model or image), Hugging Face, or MEGA. Separate multiple URLs with spaces.\n",
        "ASSET_URLS_INPUT = \"\" # @param {type:\"string\"}\n",
        "\n",
        "# @markdown **Asset Type (for non-image URLs):**\n",
        "# @markdown Select the asset type if providing a direct model URL. This is ignored for Civitai image URLs, as types are auto-detected from metadata.\n",
        "ASSET_TYPE = \"LoRA\" # @param [\"Checkpoint\", \"LoRA\", \"VAE\", \"ControlNet\", \"Upscale Model\", \"CLIP\", \"UNET\", \"TextualInversion\", \"CLIPVision\"]\n",
        "\n",
        "# @markdown **Force Re-download:**\n",
        "# @markdown If checked, files will be downloaded even if they already exist.\n",
        "FORCE_DOWNLOAD_REFRESH = False # @param {type:\"boolean\"}\n",
        "\n",
        "# --- Configuration ---\n",
        "LOCAL_BASE = '/content/ComfyUI'\n",
        "# Ensure CIVITAI_API_KEY is defined, e.g., CIVITAI_API_KEY = \"YOUR_API_KEY_HERE\"\n",
        "if 'CIVITAI_API_KEY' not in locals():\n",
        "    CIVITAI_API_KEY = \"\" # Set a default empty value if not provided\n",
        "\n",
        "SAVE_TO_GDRIVE_FLAG = 'GDRIVE_BASE' in locals() and 'SAVE_TO_GDRIVE' in locals() and SAVE_TO_GDRIVE\n",
        "BASE_PATH = GDRIVE_BASE if SAVE_TO_GDRIVE_FLAG else LOCAL_BASE\n",
        "storage_type = \"Google Drive\" if SAVE_TO_GDRIVE_FLAG else \"Colab Runtime\"\n",
        "\n",
        "subfolder_map = {\n",
        "    \"Checkpoint\": \"models/checkpoints\",\n",
        "    \"LoRA\": \"models/loras\",\n",
        "    \"VAE\": \"models/vae\",\n",
        "    \"ControlNet\": \"models/controlnet\",\n",
        "    \"Upscale Model\": \"models/upscale_models\",\n",
        "    \"CLIP\": \"models/clip\",\n",
        "    \"UNET\": \"models/unet\",\n",
        "    \"TextualInversion\": \"models/embeddings\",\n",
        "    \"CLIPVision\": \"models/clip_vision\",\n",
        "}\n",
        "\n",
        "# Mapping from Civitai API type to our subfolder key\n",
        "civitai_api_type_map = {\n",
        "    \"Checkpoint\": \"Checkpoint\",\n",
        "    \"LORA\": \"LoRA\",\n",
        "    \"VAE\": \"VAE\",\n",
        "    \"ControlNet\": \"ControlNet\",\n",
        "    \"Upscaler\": \"Upscale Model\",\n",
        "    \"TextualInversion\": \"TextualInversion\",\n",
        "    \"Hypernetwork\": \"TextualInversion\",\n",
        "    \"AestheticGradient\": \"TextualInversion\",\n",
        "}\n",
        "\n",
        "\n",
        "def sanitize_filename(name: str) -> str:\n",
        "    \"\"\"Sanitize filename by removing problematic characters.\"\"\"\n",
        "    return re.sub(r'[\\\\/:\"*?<>|(){}[\\]]+', \"_\", name)\n",
        "\n",
        "def download_with_progress(url, dest_path, api_key=None):\n",
        "    \"\"\"Download file with progress bar.\"\"\"\n",
        "    headers = {\"Authorization\": f\"Bearer {api_key}\"} if api_key else {}\n",
        "    try:\n",
        "        with requests.get(url, headers=headers, stream=True) as r:\n",
        "            r.raise_for_status()\n",
        "            total = int(r.headers.get(\"content-length\", 0))\n",
        "            with open(dest_path, \"wb\") as f, tqdm(total=total, unit=\"B\", unit_scale=True, unit_divisor=1024, desc=os.path.basename(dest_path)) as bar:\n",
        "                for chunk in r.iter_content(chunk_size=8192):\n",
        "                    if chunk:\n",
        "                        f.write(chunk)\n",
        "                        bar.update(len(chunk))\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Download failed: {e}\")\n",
        "        # Clean up partial file on failure\n",
        "        if os.path.exists(dest_path):\n",
        "            os.remove(dest_path)\n",
        "        return False\n",
        "\n",
        "def extract_model_id(url: str) -> Optional[str]:\n",
        "    \"\"\"Extract model ID from a Civitai model URL.\"\"\"\n",
        "    match = re.search(r\"models/(\\d+)\", url)\n",
        "    return match.group(1) if match else None\n",
        "\n",
        "def fetch_model_data(model_id: str, api_key: str) -> Optional[Dict[str, Any]]:\n",
        "    \"\"\"Fetch model data from Civitai API.\"\"\"\n",
        "    headers = {\"Authorization\": f\"Bearer {api_key}\"} if api_key else {}\n",
        "    api_url = f\"https://civitai.com/api/v1/models/{model_id}\"\n",
        "    try:\n",
        "        response = requests.get(api_url, headers=headers)\n",
        "        response.raise_for_status()\n",
        "        return response.json()\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        model_page_url = f\"https://civitai.com/models/{model_id}\"\n",
        "        display(Markdown(f\"❌ **API Error:** Could not fetch metadata for model ID `{model_id}`. \"\n",
        "                         f\"Please check if the model exists and is accessible: [{model_page_url}]({model_page_url})\"))\n",
        "        print(f\"   (Underlying error: {e})\")\n",
        "        return None\n",
        "\n",
        "# --- NEW HELPERS FOR CIVITAI IMAGE URLS ---\n",
        "\n",
        "def is_civitai_image_url(url: str) -> bool:\n",
        "    \"\"\"Check if the URL is a Civitai image URL.\"\"\"\n",
        "    return 'civitai.com/images/' in url\n",
        "\n",
        "def extract_civitai_image_id(url: str) -> Optional[str]:\n",
        "    \"\"\"Extract image ID from a Civitai image URL.\"\"\"\n",
        "    match = re.search(r\"images/(\\d+)\", url)\n",
        "    return match.group(1) if match else None\n",
        "\n",
        "def fetch_civitai_image_metadata(image_id: str, api_key: str) -> Optional[Dict[str, Any]]:\n",
        "    \"\"\"Fetch metadata for a specific Civitai image.\"\"\"\n",
        "    api_url = f\"https://civitai.com/api/v1/images?imageId={image_id}&nsfw=X\"\n",
        "    headers = {\"Authorization\": f\"Bearer {api_key}\"} if api_key else {}\n",
        "    try:\n",
        "        response = requests.get(api_url, headers=headers)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "        if data.get('items'):\n",
        "            return data['items'][0]\n",
        "        return None\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        image_page_url = f\"https://civitai.com/images/{image_id}\"\n",
        "        display(Markdown(f\"❌ **API Error:** Could not fetch metadata for image ID `{image_id}`. \"\n",
        "                         f\"Please check if the image is accessible: [{image_page_url}]({image_page_url})\"))\n",
        "        print(f\"   (Underlying error: {e})\")\n",
        "        return None\n",
        "\n",
        "def fetch_model_version_data(version_id: str, api_key: str) -> Optional[Dict[str, Any]]:\n",
        "    \"\"\"Fetch data for a specific model version to get file info.\"\"\"\n",
        "    api_url = f\"https://civitai.com/api/v1/model-versions/{version_id}\"\n",
        "    headers = {\"Authorization\": f\"Bearer {api_key}\"} if api_key else {}\n",
        "    try:\n",
        "        response = requests.get(api_url, headers=headers)\n",
        "        response.raise_for_status()\n",
        "        return response.json()\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"❌ Could not fetch model version data for ID {version_id}: {e}\")\n",
        "        return None\n",
        "\n",
        "def parse_civitai_image_assets(metadata: Dict[str, Any]) -> list:\n",
        "    \"\"\"Parse all unique downloadable resources from Civitai image metadata.\"\"\"\n",
        "    unique_resources = {}\n",
        "    meta = metadata.get(\"meta\")\n",
        "    if not meta: return []\n",
        "\n",
        "    # Combine all known resource fields\n",
        "    all_resources = meta.get(\"resources\", []) + meta.get(\"civitaiResources\", [])\n",
        "\n",
        "    for res in all_resources:\n",
        "        version_id = res.get('modelVersionId')\n",
        "        if version_id:\n",
        "            unique_resources[version_id] = res\n",
        "\n",
        "    # Handle 'additionalResources' in URN format\n",
        "    for res in meta.get(\"additionalResources\", []):\n",
        "        urn_match = re.search(r'civitai:\\d+@(\\d+)', res.get(\"name\", \"\"))\n",
        "        if urn_match:\n",
        "            version_id = int(urn_match.group(1))\n",
        "            if version_id not in unique_resources:\n",
        "                unique_resources[version_id] = {'modelVersionId': version_id, 'type': res.get('type')}\n",
        "\n",
        "    return list(unique_resources.values())\n",
        "\n",
        "# --- Check and Install Dependencies for MEGA and Hugging Face ---\n",
        "needs_hf_mega_deps = any('civitai.com' not in urlparse(url).netloc for url in ASSET_URLS_INPUT.split())\n",
        "if needs_hf_mega_deps:\n",
        "    print(\"📦 Checking dependencies for MEGA and Hugging Face...\")\n",
        "    try:\n",
        "        import huggingface_hub\n",
        "        print(\"✅ huggingface_hub is already installed.\")\n",
        "    except ImportError:\n",
        "        print(\"📦 Installing huggingface_hub...\")\n",
        "        get_ipython().system('pip install -q huggingface_hub')\n",
        "\n",
        "    if shutil.which('megadl'):\n",
        "        print(\"✅ megatools is already installed.\")\n",
        "    else:\n",
        "        print(\"📦 Installing megatools...\")\n",
        "        get_ipython().system('apt -y update -qq && apt -y install -qq megatools')\n",
        "\n",
        "# --- Download Logic ---\n",
        "asset_urls = ASSET_URLS_INPUT.split()\n",
        "\n",
        "if asset_urls:\n",
        "    print(f\"🚀 Starting Universal Asset Downloader for {len(asset_urls)} URL(s)...\")\n",
        "\n",
        "    for ASSET_URL in asset_urls:\n",
        "        ASSET_URL = ASSET_URL.strip()\n",
        "        if not ASSET_URL: continue\n",
        "\n",
        "        domain = urlparse(ASSET_URL).netloc.lower()\n",
        "        print(f\"\\n--- Processing URL: {ASSET_URL} ---\")\n",
        "\n",
        "        if 'civitai.com' in domain:\n",
        "            if not CIVITAI_API_KEY:\n",
        "                print(\"❌ Civitai API key is missing. Please set CIVITAI_API_KEY. Skipping download.\")\n",
        "                continue\n",
        "\n",
        "            # --- HANDLE CIVITAI IMAGE URL ---\n",
        "            if is_civitai_image_url(ASSET_URL):\n",
        "                image_id = extract_civitai_image_id(ASSET_URL)\n",
        "                if not image_id:\n",
        "                    print(f\"❌ Invalid Civitai image URL: {ASSET_URL}\")\n",
        "                    continue\n",
        "\n",
        "                display(Markdown(f\"🎨 **Analyzing Civitai Image:** [{ASSET_URL}]({ASSET_URL})\"))\n",
        "                image_meta = fetch_civitai_image_metadata(image_id, CIVITAI_API_KEY)\n",
        "\n",
        "                if not image_meta or not image_meta.get(\"meta\"):\n",
        "                    print(f\"❌ No generation metadata found for image {image_id}.\")\n",
        "                    continue\n",
        "\n",
        "                resources_to_download = parse_civitai_image_assets(image_meta)\n",
        "                if not resources_to_download:\n",
        "                    print(f\"ℹ️ No downloadable resources found in the image's metadata.\")\n",
        "                    continue\n",
        "\n",
        "                print(f\"Found {len(resources_to_download)} unique assets to download from image metadata.\")\n",
        "                for resource in resources_to_download:\n",
        "                    version_id = resource.get('modelVersionId')\n",
        "                    version_data = fetch_model_version_data(str(version_id), CIVITAI_API_KEY)\n",
        "                    if not version_data: continue\n",
        "\n",
        "                    model_type = version_data.get('model', {}).get('type', 'Checkpoint')\n",
        "                    asset_type_key = civitai_api_type_map.get(model_type, \"Checkpoint\")\n",
        "                    subfolder = subfolder_map.get(asset_type_key)\n",
        "\n",
        "                    files = version_data.get('files', [])\n",
        "                    if not files: continue\n",
        "\n",
        "                    best_file = next((f for f in files if '.safetensors' in f.get('name', '').lower()), files[0])\n",
        "                    file_name = sanitize_filename(best_file.get('name'))\n",
        "                    download_url = best_file.get('downloadUrl')\n",
        "                    model_page_url = f\"https://civitai.com/models/{version_data.get('modelId')}\"\n",
        "                    model_name_link = f\"**[{version_data.get('model', {}).get('name')}]({model_page_url})**\"\n",
        "\n",
        "                    display(Markdown(f\"   - **{asset_type_key}:** {model_name_link} (Version: *{version_data.get('name')}*)\"))\n",
        "\n",
        "                    destination_path = os.path.join(BASE_PATH, subfolder, file_name)\n",
        "                    os.makedirs(os.path.dirname(destination_path), exist_ok=True)\n",
        "\n",
        "                    if not os.path.isfile(destination_path) or FORCE_DOWNLOAD_REFRESH:\n",
        "                        print(f\"     ↳ Saving as \\033[1m{file_name}\\033[0m to → {subfolder} (in {storage_type})\")\n",
        "                        if download_with_progress(download_url, destination_path, CIVITAI_API_KEY):\n",
        "                            print(f\"     ✅ Finished\")\n",
        "                    else:\n",
        "                        print(f\"     🔍 \\033[90m{file_name}\\033[0m already exists in {storage_type} — skipping.\")\n",
        "\n",
        "            # --- HANDLE CIVITAI MODEL URL ---\n",
        "            else:\n",
        "                model_id = extract_model_id(ASSET_URL)\n",
        "                if not model_id:\n",
        "                    print(f\"❌ Invalid Civitai model URL: {ASSET_URL}\")\n",
        "                    continue\n",
        "\n",
        "                model_info = fetch_model_data(model_id, CIVITAI_API_KEY)\n",
        "                if not model_info: continue\n",
        "\n",
        "                model_name_hyperlink = f\"**[{model_info.get('name', 'Unknown Model')}]({ASSET_URL})**\"\n",
        "                display(Markdown(f\"\\n🚀 Downloading model: {model_name_hyperlink}\"))\n",
        "\n",
        "                version_id_match = re.search(r\"modelVersionId=(\\d+)\", ASSET_URL)\n",
        "                target_version_id = int(version_id_match.group(1)) if version_id_match else None\n",
        "                target_version = None\n",
        "\n",
        "                if target_version_id:\n",
        "                    target_version = next((v for v in model_info.get('modelVersions', []) if v.get('id') == target_version_id), None)\n",
        "                else:\n",
        "                    target_version = model_info.get('modelVersions', [None])[0]\n",
        "\n",
        "                if not target_version:\n",
        "                    print(f\"❌ Could not find the specified model version. Skipping.\")\n",
        "                    continue\n",
        "\n",
        "                files = target_version.get('files', [])\n",
        "                if not files:\n",
        "                    print(f\"❌ No files found for this model version. Skipping.\")\n",
        "                    continue\n",
        "\n",
        "                best_file = next((f for f in files if '.safetensors' in f.get('name', '').lower()), files[0])\n",
        "                file_name = sanitize_filename(best_file.get('name'))\n",
        "                download_url = best_file.get('downloadUrl')\n",
        "                subfolder = subfolder_map.get(ASSET_TYPE)\n",
        "                destination_path = os.path.join(BASE_PATH, subfolder, file_name)\n",
        "                os.makedirs(os.path.dirname(destination_path), exist_ok=True)\n",
        "\n",
        "                if not os.path.isfile(destination_path) or FORCE_DOWNLOAD_REFRESH:\n",
        "                    print(f\"   ↳ Saving as \\033[1m{file_name}\\033[0m to → {subfolder} (in {storage_type})\")\n",
        "                    if download_with_progress(download_url, destination_path, CIVITAI_API_KEY):\n",
        "                        print(f\"✅ Finished\")\n",
        "                else:\n",
        "                    print(f\"🔍 \\033[90m{file_name}\\033[0m already exists in {storage_type} — skipping.\")\n",
        "\n",
        "        elif 'huggingface.co' in domain:\n",
        "            if 'HF_TOKEN' not in locals() or not HF_TOKEN: HF_TOKEN = \"\"\n",
        "            from huggingface_hub import hf_hub_download, HfApi\n",
        "            display(Markdown(f\"\\n🚀 Downloading from **Hugging Face**\"))\n",
        "            path_parts = urlparse(ASSET_URL).path.strip('/').split('/')\n",
        "            repo_id = f\"{path_parts[0]}/{path_parts[1]}\" if len(path_parts) >= 2 else None\n",
        "            file_path_in_repo = None\n",
        "            subfolder = subfolder_map.get(ASSET_TYPE)\n",
        "\n",
        "            if repo_id:\n",
        "                if len(path_parts) > 3 and path_parts[2] in ['blob', 'resolve']:\n",
        "                    file_path_in_repo = '/'.join(path_parts[4:])\n",
        "                else:\n",
        "                    try:\n",
        "                        files = HfApi().list_repo_files(repo_id=repo_id, token=HF_TOKEN)\n",
        "                        safetensor_files = [f for f in files if f.lower().endswith(('.safetensors', '.bin', '.pth'))]\n",
        "                        if safetensor_files:\n",
        "                            file_path_in_repo = safetensor_files[0]\n",
        "                            print(f\"ℹ️ Auto-selected file: {file_path_in_repo}\")\n",
        "                        else:\n",
        "                            print(f\"❌ No suitable model file found in {repo_id}. Skipping.\")\n",
        "                    except Exception as e:\n",
        "                         print(f\"❌ Failed to list files in Hugging Face repo {repo_id}: {e}. Skipping.\")\n",
        "\n",
        "                if file_path_in_repo:\n",
        "                    file_name = sanitize_filename(os.path.basename(file_path_in_repo))\n",
        "                    destination_path = os.path.join(BASE_PATH, subfolder, file_name)\n",
        "                    if not os.path.isfile(destination_path) or FORCE_DOWNLOAD_REFRESH:\n",
        "                        print(f\"   ↳ Saving as \\033[1m{file_name}\\033[0m to → {subfolder} (in {storage_type})\")\n",
        "                        try:\n",
        "                            hf_hub_download(repo_id=repo_id, filename=file_path_in_repo, local_dir=os.path.join(BASE_PATH, subfolder), local_dir_use_symlinks=False, token=HF_TOKEN, force_download=FORCE_DOWNLOAD_REFRESH)\n",
        "                            print(f\"✅ Finished\")\n",
        "                        except Exception as e:\n",
        "                            print(f\"❌ Hugging Face download failed: {e}\")\n",
        "                    else:\n",
        "                        print(f\"🔍 \\033[90m{file_name}\\033[0m already exists in {storage_type} — skipping.\")\n",
        "                else:\n",
        "                    print(\"❌ Could not determine a file to download from the Hugging Face URL.\")\n",
        "            else:\n",
        "                print(f\"❌ Invalid Hugging Face URL: {ASSET_URL}\")\n",
        "\n",
        "        elif 'mega.nz' in domain:\n",
        "            subfolder = subfolder_map.get(ASSET_TYPE)\n",
        "            destination_folder = os.path.join(BASE_PATH, subfolder)\n",
        "            display(Markdown(f\"\\n🚀 Downloading from **MEGA** to → {subfolder} (in {storage_type})\"))\n",
        "            try:\n",
        "                subprocess.run(['megadl', ASSET_URL, '--path', destination_folder], check=True, capture_output=True, text=True)\n",
        "                print(f\"✅ Finished\")\n",
        "            except subprocess.CalledProcessError as e:\n",
        "                if \"File exists\" in e.stderr:\n",
        "                    print(f\"🔍 File already exists in {storage_type} — skipping.\")\n",
        "                else:\n",
        "                    print(f\"❌ MEGA download failed: {e.stderr}\")\n",
        "            except Exception as e:\n",
        "                print(f\"❌ Failed to download from MEGA: {e}\")\n",
        "\n",
        "        else:\n",
        "            print(f\"ℹ️ Unsupported domain: {domain}. Use a MEGA, Hugging Face, or Civitai URL.\")\n",
        "else:\n",
        "    print(\"ℹ️ No Asset URL(s) provided. Skipping download.\")\n",
        "\n",
        "print(\"\\n🎉 Universal Asset download section complete.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ed078d74"
      },
      "source": [
        "* * *\n",
        "\n",
        "\n",
        "## ⬇️ Download WAN Models (Hugging Face & Civitai)\n",
        "\n",
        "Download specific WAN models for video generation from Hugging Face and Civitai.\n",
        "\n",
        "**Important Note on Model Types (GGUF vs. FP8):**\n",
        "\n",
        "* **GGUF Models:** These are highly quantized models primarily optimized for VRAM savings. They are excellent if you have limited GPU memory.\n",
        "* **FP8 Models:** These models use 8-bit floating-point quantization. **On `T4` GPUs and other GPUs with FP8 support, FP8 models can offer significantly faster inference times compared to GGUF.** While they may use slightly more VRAM than the most aggressive GGUF quantizations, the speedup can be substantial.\n",
        "\n",
        "For faster generation on `T4` GPUs, it's recommended to download and use the **FP8 UNet model** and load it using the **native `Load Diffusion Model` node** (NOT the ComfyUI-GGUF loader). When loading the FP8 model in the `Load Diffusion Model` node, make sure to set the `weight_type` parameter to `fp8_fast`. This is key to unlocking the performance benefits of FP8.\n",
        "\n",
        "# **Side Note:** With this [workflow](https://gist.github.com/thaakeno/7960b2a435d8bcb05c4bd9e47eeb4dea) using the WAN 2.2 Q4 GGUF models (both T2V and I2V) and a paid `L4` GPU, generation times averaged around **80–110 seconds per 5 seconds of video**.\n",
        "\n",
        "---\n",
        "\n",
        "Let me know if you want to highlight the speed benchmarks more or move the side note elsewhere.\n",
        "\n",
        "\n",
        "### **Important Note on 14B Models:**\n",
        "\n",
        "<span style=\"color:#FF6347; font-weight:bold;\">⚠️ VRAM WARNING for 14B Models ⚠️</span>\n",
        "\n",
        "The 14B WAN models are very large. A `T4` GPU is **NOT sufficient** for these models.\n",
        "\n",
        "To use 14B models, you will need a GPU with significantly more VRAM, such as an `A100` or `L4` (typically available with Google Colab Pro/Pro+) or sufficient VRAM on your local machine.\n",
        "\n",
        "* * *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "2v69gB2sYpvs"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import requests\n",
        "from tqdm.notebook import tqdm\n",
        "from pathlib import Path\n",
        "from urllib.parse import urlparse\n",
        "import shutil\n",
        "from typing import Optional, Dict, Any\n",
        "from IPython.display import display, Markdown\n",
        "import re\n",
        "from huggingface_hub import hf_hub_download\n",
        "\n",
        "# @title 📥  WAN 2.1 & 2.2 Model Downloader (Hugging Face & Civitai)\n",
        "\n",
        "# @markdown This versatile cell allows you to download various WAN models, VAEs, Text Encoders,\n",
        "# @markdown and LoRAs directly into your ComfyUI setup. Simply select the components you need and run the cell!\n",
        "\n",
        "# --- ⚙️ Configuration ---\n",
        "LOCAL_BASE = '/content/ComfyUI' # Default local storage for Colab Runtime\n",
        "# Determines if models should be saved to Google Drive (if mounted and enabled) or Colab Runtime.\n",
        "# Ensure 'GDRIVE_BASE' and 'SAVE_TO_GDRIVE' variables are defined and set in a previous cell if you want to use Google Drive.\n",
        "SAVE_TO_GDRIVE_FLAG = 'GDRIVE_BASE' in locals() and 'SAVE_TO_GDRIVE' in locals() and SAVE_TO_GDRIVE\n",
        "BASE_PATH = GDRIVE_BASE if SAVE_TO_GDRIVE_FLAG else LOCAL_BASE\n",
        "storage_type = \"Google Drive\" if SAVE_TO_GDRIVE_FLAG else \"Colab Runtime\"\n",
        "\n",
        "# Initialize API tokens for Hugging Face and Civitai.\n",
        "# For security, consider setting these in Colab Secrets (Left-hand menu -> 🔑 Secrets)\n",
        "# and mapping them as environment variables (e.g., HF_TOKEN, CIVITAI_API_KEY).\n",
        "# If not set elsewhere, they will default to empty strings here.\n",
        "if 'HF_TOKEN' not in locals():\n",
        "    HF_TOKEN = \"\"\n",
        "if 'CIVITAI_API_KEY' not in locals():\n",
        "    CIVITAI_API_KEY = \"\"\n",
        "\n",
        "# @markdown ---\n",
        "# @markdown ### 🔄 Global Download Settings\n",
        "# @markdown **Force Re-download:**\n",
        "# @markdown If checked, any selected file will be downloaded again, even if it already exists locally.\n",
        "FORCE_DOWNLOAD_REFRESH = False # @param {type:\"boolean\"}\n",
        "\n",
        "# @markdown ---\n",
        "# @markdown ### 🤖 WAN 2.1 Models (1.3B Parameters)\n",
        "# @markdown These models are generally lighter and suitable for systems with less VRAM.\n",
        "\n",
        "# @markdown **UNet GGUF Model (1.3B):** Quantized for efficient Text-to-Video generation.\n",
        "download_wan_unet_gguf_1_3b = False # @param {type:\"boolean\"}\n",
        "# @markdown **UNet FP8 Model (1.3B):** Float8 quantized for faster inference on T4 GPUs (Text-to-Video).\n",
        "download_wan_unet_fp8_1_3b = False # @param {type:\"boolean\"}\n",
        "# @markdown **CausVid LoRA (1.3B):** LoRA specifically trained for causal video generation.\n",
        "download_wan_causvid_lora_1_3b = False # @param {type:\"boolean\"}\n",
        "# @markdown **CLIP Vision (1.3B):** Vision model for understanding images/frames in video generation.\n",
        "download_wan_clip_vision_1_3b = False # @param {type:\"boolean\"}\n",
        "# @markdown **Wan 2.1-Fun-1.3B-InP (Civitai):** An Image-to-Video model optimized for inpainting and general i2v tasks, reuploaded on Civitai.\n",
        "download_wan_fun_inp_civitai_1_3b = False # @param {type:\"boolean\"}\n",
        "\n",
        "# @markdown ---\n",
        "# @markdown ### 🌟 WAN 2.1 Models (14B Parameters)\n",
        "# @markdown Higher quality models, recommended for systems with more VRAM.\n",
        "\n",
        "# @markdown **Wan 2.1 T2V GGUF (14B):** Main Text-to-Video model (Quantized).\n",
        "download_wan_t2v_gguf_14b = False # @param {type:\"boolean\"}\n",
        "# @markdown **Wan 2.1 I2V GGUF (14B, 480p):** Main Image-to-Video model optimized for 480p (Quantized).\n",
        "download_wan_i2v_gguf_14b_480p = False # @param {type:\"boolean\"}\n",
        "# @markdown **Wan 2.1 FLF2V GGUF (14B, 720p):** First/Last Frame Image-to-Video model optimized for 720p (Quantized).\n",
        "download_wan_flf2v_gguf_14b_720p = False # @param {type:\"boolean\"}\n",
        "# @markdown **Wan 2.1 VACE GGUF (14B):** The Video-Control model (Quantized).\n",
        "download_wan_vace_gguf_14b = False # @param {type:\"boolean\"}\n",
        "# @markdown **CausVid LoRA (14B):** LoRA specifically trained for faster video generation at lower steps (eg. 6-8 , CFG 1)\n",
        "download_wan_causvid_lora_14b = False # @param {type:\"boolean\"}\n",
        "\n",
        "# @markdown ---\n",
        "# @markdown ### ✨ WAN 2.2 Models (Latest Generation)\n",
        "# @markdown The newest models offering improved performance and features.\n",
        "\n",
        "# @markdown **WAN 2.2 TI2V 5B (FP16):** Text-Image-to-Video model.\n",
        "download_wan22_ti2v_5b_fp16 = False # @param {type:\"boolean\"}\n",
        "# @markdown **WAN 2.2 TI2V 5B (Q8_0 GGUF):** Quantized GGUF version (Q8_0) of the TI2V model.\n",
        "download_wan22_ti2v_5b_q8_gguf = False # @param {type:\"boolean\"}\n",
        "# @markdown **WAN 2.2 TI2V 5B (Q4_K_M GGUF):** Quantized GGUF version (Q4_K_M) of the TI2V model.\n",
        "download_wan22_ti2v_5b_q4km_gguf = False # @param {type:\"boolean\"}\n",
        "\n",
        "# @markdown **WAN 2.2 T2V Low Noise 14B (FP8 Scaled):** Text-to-Video low noise model.\n",
        "download_wan22_t2v_low_noise_14b_fp8 = False # @param {type:\"boolean\"}\n",
        "# @markdown **WAN 2.2 T2V Low Noise 14B (Q4_K_M GGUF):** Quantized GGUF version (Q4_K_M) of the T2V low noise model.\n",
        "download_wan22_t2v_low_noise_14b_q4km_gguf = False # @param {type:\"boolean\"}\n",
        "# @markdown **WAN 2.2 T2V High Noise 14B (Q4_K_M GGUF):** Quantized GGUF version (Q4_K_M) of the T2V high noise model.\n",
        "download_wan22_t2v_high_noise_14b_q4km_gguf = False # @param {type:\"boolean\"}\n",
        "\n",
        "# @markdown **WAN 2.2 I2V High Noise 14B (FP8 Scaled):** Image-to-Video high noise model.\n",
        "download_wan22_i2v_high_noise_14b_fp8 = False # @param {type:\"boolean\"}\n",
        "# @markdown **WAN 2.2 I2V High Noise 14B (Q4_K_M GGUF):** Quantized GGUF version (Q4_K_M) of the I2V high noise model.\n",
        "download_wan22_i2v_high_noise_14b_q4km_gguf = False # @param {type:\"boolean\"}\n",
        "# @markdown **WAN 2.2 I2V Low Noise 14B (FP16):** Image-to-Video low noise model.\n",
        "download_wan22_i2v_low_noise_14b_fp16 = False # @param {type:\"boolean\"}\n",
        "# @markdown **WAN 2.2 I2V Low Noise 14B (Q4_K_M GGUF):** Quantized GGUF version (Q4_K_M) of the I2V low noise model.\n",
        "download_wan22_i2v_low_noise_14b_q4km_gguf = False # @param {type:\"boolean\"}\n",
        "\n",
        "# @markdown ---\n",
        "# @markdown ### 📚 Core Components (Text Encoders & VAEs)\n",
        "# @markdown Essential components for all WAN models.\n",
        "\n",
        "# @markdown **UMT5 XXL FP8 Scaled (Text Encoder, WAN 2.1):** The main text encoder for WAN 2.1 models (faster, uses more VRAM).\n",
        "download_umt5_encoder_21 = False # @param {type:\"boolean\"}\n",
        "# @markdown **UMT5 XXL FP8 Scaled (Text Encoder, WAN 2.2):** The main text encoder for WAN 2.2 models (faster, uses more VRAM).\n",
        "download_umt5_encoder_22 = False # @param {type:\"boolean\"}\n",
        "# @markdown **UMT5 XXL Text Encoder (GGUF):** Alternative GGUF version (slower, uses less VRAM/RAM), compatible with both 2.1 and 2.2.\n",
        "download_umt5_gguf_encoder = False # @param {type:\"boolean\"}\n",
        "# @markdown **WAN 2.1 VAE:** The VAE model used for encoding and decoding images/frames (Compatible with 1.3B/14B WAN 2.1 models).\n",
        "download_wan_vae_21 = False # @param {type:\"boolean\"}\n",
        "# @markdown **WAN 2.1 VAE GGUF (1.3B VACE):** A quantized VAE (1.3B VACE) compatible with 14B models.\n",
        "download_wan_vae_gguf_14b_vace = False # @param {type:\"boolean\"}\n",
        "# @markdown **WAN 2.2 VAE:** The VAE model specifically for WAN 2.2 models.\n",
        "download_wan_vae_22 = False # @param {type:\"boolean\"}\n",
        "\n",
        "# @markdown ---\n",
        "# @markdown ### 🎨 LoRAs\n",
        "# @markdown Additional models to enhance style, characters, or performance.\n",
        "\n",
        "# @markdown **Pusa V1 LoRA:** A high quality motion LoRA for WAN 14B models.\n",
        "download_pusa_v1_lora = False # @param {type:\"boolean\"}\n",
        "# @markdown **Lightx2v I2V LoRA (Rank 128):** A speed/distillation LoRA for I2V (14B, 480p, Rank 128).\n",
        "download_lightx2v_i2v_lora_rank128 = False # @param {type:\"boolean\"}\n",
        "# @markdown **Lightx2v T2V LoRA (14B, Rank 64):** A speed/distillation LoRA for T2V (14B, Rank 64).\n",
        "download_lightx2v_t2v_lora_rank64 = False # @param {type:\"boolean\"}\n",
        "# @markdown **Lightx2v I2V LoRA (480p, Rank 64):** A speed/distillation LoRA for I2V (480p, Rank 64).\n",
        "download_lightx2v_i2v_480p_lora_rank64 = False # @param {type:\"boolean\"}\n",
        "# @markdown **Phantom-FusioniX LoRA:** Combines WAN 2.1 Phantom and FusionX styles.\n",
        "download_phantom_fusionix_lora = False # @param {type:\"boolean\"}\n",
        "# @markdown **Lightx2v T2V LoRA (14B, Rank 256):** A speed/distillation LoRA for T2V (14B, Rank 256).\n",
        "download_lightx2v_t2v_lora_rank256 = False # @param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "# --- Helper Functions (for Civitai Downloads) ---\n",
        "def extract_model_id(url: str) -> Optional[str]:\n",
        "    \"\"\"Extracts the model ID from a Civitai model URL.\"\"\"\n",
        "    match = re.search(r\"models/(\\d+)\", url)\n",
        "    return match.group(1) if match else None\n",
        "\n",
        "def fetch_model_data(model_id: str, api_key: str) -> Optional[Dict[str, Any]]:\n",
        "    \"\"\"Fetches model metadata from the Civitai API.\"\"\"\n",
        "    headers = {\"Authorization\": f\"Bearer {api_key}\"} if api_key else {}\n",
        "    api_url = f\"https://civitai.com/api/v1/models/{model_id}\"\n",
        "    try:\n",
        "        response = requests.get(api_url, headers=headers)\n",
        "        response.raise_for_status()\n",
        "        return response.json()\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        model_page_url = f\"https://civitai.com/models/{model_id}\"\n",
        "        display(Markdown(f\"❌ **API Error:** Could not fetch metadata for model ID `{model_id}`. \"\n",
        "                         f\"Please check if the model exists and is accessible: [{model_page_url}]({model_page_url})\"))\n",
        "        print(f\"   (Underlying error: {e})\")\n",
        "        return None\n",
        "\n",
        "def sanitize_filename(name: str) -> str:\n",
        "    \"\"\"Removes invalid characters from a filename.\"\"\"\n",
        "    return re.sub(r'[\\\\/:\"*?<>|(){}[\\]]+', \"_\", name)\n",
        "\n",
        "def download_file_with_progress_util(url: str, output_path: Path, api_key: Optional[str]) -> int:\n",
        "    \"\"\"Downloads a file with a progress bar, suitable for Civitai direct downloads.\"\"\"\n",
        "    headers = {\"Authorization\": f\"Bearer {api_key}\"} if api_key else {}\n",
        "    total_downloaded = 0\n",
        "    try:\n",
        "        response = requests.get(url, headers=headers, stream=True)\n",
        "        response.raise_for_status()\n",
        "        total_size = int(response.headers.get(\"content-length\", 0))\n",
        "        with open(output_path, \"wb\") as file, tqdm(desc=output_path.name, total=total_size, unit='B', unit_scale=True, unit_divisor=1024) as bar:\n",
        "            for chunk in response.iter_content(chunk_size=8192):\n",
        "                size = file.write(chunk)\n",
        "                bar.update(size)\n",
        "        total_downloaded = output_path.stat().st_size\n",
        "        return total_downloaded\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Download failed for {output_path.name}: {e}\")\n",
        "        # Clean up partial download if it exists\n",
        "        if output_path.exists():\n",
        "            output_path.unlink()\n",
        "        return 0\n",
        "\n",
        "\n",
        "# --- Unified Model Definitions ---\n",
        "# This dictionary contains all WAN model components with their download details.\n",
        "all_wan_assets = {\n",
        "    # WAN 2.1 Models (1.3B)\n",
        "    \"UNet GGUF Model (1.3B)\": {\n",
        "        \"source\": \"huggingface\", \"repo_id\": \"samuelchristlie/Wan2.1-T2V-1.3B-GGUF\",\n",
        "        \"filename\": \"Wan2.1-T2V-1.3B-Q4_K_M.gguf\", \"subfolder\": \"models/unet\",\n",
        "        \"enabled\": download_wan_unet_gguf_1_3b\n",
        "    },\n",
        "    \"UNet FP8 Model (1.3B)\": {\n",
        "        \"source\": \"huggingface\", \"repo_id\": \"Kijai/WanVideo_comfy\",\n",
        "        \"filename\": \"Wan2_1-T2V-1_3B_fp8_e4m3fn.safetensors\", \"subfolder\": \"models/unet\",\n",
        "        \"enabled\": download_wan_unet_fp8_1_3b\n",
        "    },\n",
        "    \"CausVid LoRA (1.3B)\": {\n",
        "        \"source\": \"huggingface\", \"repo_id\": \"Kijai/WanVideo_comfy\",\n",
        "        \"filename\": \"Wan21_CausVid_bidirect2_T2V_1_3B_lora_rank32.safetensors\", \"subfolder\": \"models/loras\",\n",
        "        \"enabled\": download_wan_causvid_lora_1_3b\n",
        "    },\n",
        "    \"CLIP Vision (1.3B)\": {\n",
        "        \"source\": \"huggingface\", \"repo_id\": \"Comfy-Org/Wan_2.1_ComfyUI_repackaged\",\n",
        "        \"filename\": \"split_files/clip_vision/clip_vision_h.safetensors\", \"subfolder\": \"models/clip_vision\",\n",
        "        \"enabled\": download_wan_clip_vision_1_3b\n",
        "    },\n",
        "    \"Wan 2.1-Fun-1.3B-InP (Civitai)\": {\n",
        "        \"source\": \"civitai\", \"page_url\": \"https://civitai.com/models/1450534?modelVersionId=1640053\",\n",
        "        \"subfolder\": \"models/unet\",\n",
        "        \"enabled\": download_wan_fun_inp_civitai_1_3b\n",
        "    },\n",
        "\n",
        "    # WAN 2.1 Models (14B)\n",
        "    \"Wan 2.1 T2V GGUF (14B)\": {\n",
        "        \"source\": \"huggingface\", \"repo_id\": \"city96/Wan2.1-T2V-14B-gguf\",\n",
        "        \"filename\": \"wan2.1-t2v-14b-Q4_K_M.gguf\", \"subfolder\": \"models/unet\",\n",
        "        \"enabled\": download_wan_t2v_gguf_14b\n",
        "    },\n",
        "    \"Wan 2.1 I2V GGUF (14B, 480p)\": {\n",
        "        \"source\": \"huggingface\", \"repo_id\": \"calcuis/wan-gguf\",\n",
        "        \"filename\": \"wan2.1-i2v-14b-480p-q4_k_m.gguf\", \"subfolder\": \"models/unet\",\n",
        "        \"enabled\": download_wan_i2v_gguf_14b_480p\n",
        "    },\n",
        "    \"Wan 2.1 FLF2V GGUF (14B, 720p)\": {\n",
        "        \"source\": \"huggingface\", \"repo_id\": \"calcuis/wan-gguf\",\n",
        "        \"filename\": \"wan2.1-flf2v-720p-14b-q4_k_m.gguf\", \"subfolder\": \"models/unet\",\n",
        "        \"enabled\": download_wan_flf2v_gguf_14b_720p\n",
        "    },\n",
        "    \"Wan 2.1 VACE GGUF (14B)\": {\n",
        "        \"source\": \"huggingface\", \"repo_id\": \"QuantStack/Wan2.1_14B_VACE-GGUF\",\n",
        "        \"filename\": \"Wan2.1_14B_VACE-Q4_K_M.gguf\", \"subfolder\": \"models/unet\",\n",
        "        \"enabled\": download_wan_vace_gguf_14b\n",
        "    },\n",
        "    \"CausVid LoRA (14B)\": {\n",
        "        \"source\": \"huggingface\", \"repo_id\": \"Kijai/WanVideo_comfy\",\n",
        "        \"filename\": \"Wan21_CausVid_14B_T2V_lora_rank32.safetensors\", \"subfolder\": \"models/loras\",\n",
        "        \"enabled\": download_wan_causvid_lora_14b\n",
        "    },\n",
        "\n",
        "    # WAN 2.2 Models\n",
        "    \"WAN 2.2 TI2V 5B (FP16)\": {\n",
        "        \"source\": \"huggingface\", \"repo_id\": \"Comfy-Org/Wan_2.2_ComfyUI_Repackaged\",\n",
        "        \"filename\": \"split_files/diffusion_models/wan2.2_ti2v_5B_fp16.safetensors\", \"subfolder\": \"models/unet\",\n",
        "        \"enabled\": download_wan22_ti2v_5b_fp16\n",
        "    },\n",
        "    \"WAN 2.2 TI2V 5B (Q8_0 GGUF)\": {\n",
        "        \"source\": \"huggingface\", \"repo_id\": \"QuantStack/Wan2.2-TI2V-5B-GGUF\",\n",
        "        \"filename\": \"Wan2.2-TI2V-5B-Q8_0.gguf\", \"subfolder\": \"models/unet\",\n",
        "        \"enabled\": download_wan22_ti2v_5b_q8_gguf\n",
        "    },\n",
        "    \"WAN 2.2 TI2V 5B (Q4_K_M GGUF)\": {\n",
        "        \"source\": \"huggingface\", \"repo_id\": \"QuantStack/Wan2.2-TI2V-5B-GGUF\",\n",
        "        \"filename\": \"Wan2.2-TI2V-5B-Q4_K_M.gguf\", \"subfolder\": \"models/unet\",\n",
        "        \"enabled\": download_wan22_ti2v_5b_q4km_gguf\n",
        "    },\n",
        "    \"WAN 2.2 T2V Low Noise 14B (FP8 Scaled)\": {\n",
        "        \"source\": \"huggingface\", \"repo_id\": \"Comfy-Org/Wan_2.2_ComfyUI_Repackaged\",\n",
        "        \"filename\": \"split_files/diffusion_models/wan2.2_t2v_low_noise_14B_fp8_scaled.safetensors\", \"subfolder\": \"models/unet\",\n",
        "        \"enabled\": download_wan22_t2v_low_noise_14b_fp8\n",
        "    },\n",
        "    \"WAN 2.2 T2V Low Noise 14B (Q4_K_M GGUF)\": {\n",
        "        \"source\": \"huggingface\", \"repo_id\": \"QuantStack/Wan2.2-T2V-A14B-GGUF\",\n",
        "        \"filename\": \"LowNoise/Wan2.2-T2V-A14B-LowNoise-Q4_K_M.gguf\", \"subfolder\": \"models/unet\",\n",
        "        \"enabled\": download_wan22_t2v_low_noise_14b_q4km_gguf\n",
        "    },\n",
        "    \"WAN 2.2 T2V High Noise 14B (Q4_K_M GGUF)\": {\n",
        "        \"source\": \"huggingface\", \"repo_id\": \"QuantStack/Wan2.2-T2V-A14B-GGUF\",\n",
        "        \"filename\": \"HighNoise/Wan2.2-T2V-A14B-HighNoise-Q4_K_M.gguf\", \"subfolder\": \"models/unet\",\n",
        "        \"enabled\": download_wan22_t2v_high_noise_14b_q4km_gguf\n",
        "    },\n",
        "    \"WAN 2.2 I2V High Noise 14B (FP8 Scaled)\": {\n",
        "        \"source\": \"huggingface\", \"repo_id\": \"Comfy-Org/Wan_2.2_ComfyUI_Repackaged\",\n",
        "        \"filename\": \"split_files/diffusion_models/wan2.2_i2v_high_noise_14B_fp8_scaled.safetensors\", \"subfolder\": \"models/unet\",\n",
        "        \"enabled\": download_wan22_i2v_high_noise_14b_fp8\n",
        "    },\n",
        "    \"WAN 2.2 I2V High Noise 14B (Q4_K_M GGUF)\": {\n",
        "        \"source\": \"huggingface\", \"repo_id\": \"bullerwins/Wan2.2-I2V-A14B-GGUF\",\n",
        "        \"filename\": \"wan2.2_i2v_high_noise_14B_Q4_K_M.gguf\", \"subfolder\": \"models/unet\",\n",
        "        \"enabled\": download_wan22_i2v_high_noise_14b_q4km_gguf\n",
        "    },\n",
        "    \"WAN 2.2 I2V Low Noise 14B (FP16)\": {\n",
        "        \"source\": \"huggingface\", \"repo_id\": \"Comfy-Org/Wan_2.2_ComfyUI_Repackaged\",\n",
        "        \"filename\": \"split_files/diffusion_models/wan2.2_i2v_low_noise_14B_fp16.safetensors\", \"subfolder\": \"models/unet\",\n",
        "        \"enabled\": download_wan22_i2v_low_noise_14b_fp16\n",
        "    },\n",
        "    \"WAN 2.2 I2V Low Noise 14B (Q4_K_M GGUF)\": {\n",
        "        \"source\": \"huggingface\", \"repo_id\": \"bullerwins/Wan2.2-I2V-A14B-GGUF\",\n",
        "        \"filename\": \"wan2.2_i2v_low_noise_14B_Q4_K_M.gguf\", \"subfolder\": \"models/unet\",\n",
        "        \"enabled\": download_wan22_i2v_low_noise_14b_q4km_gguf\n",
        "    },\n",
        "\n",
        "    # Core Components (Text Encoders & VAEs)\n",
        "    \"UMT5 XXL FP8 Scaled (Text Encoder, WAN 2.1)\": {\n",
        "        \"source\": \"huggingface\", \"repo_id\": \"Comfy-Org/Wan_2.1_ComfyUI_repackaged\",\n",
        "        \"filename\": \"split_files/text_encoders/umt5_xxl_fp8_e4m3fn_scaled.safetensors\", \"subfolder\": \"models/clip\",\n",
        "        \"enabled\": download_umt5_encoder_21\n",
        "    },\n",
        "    \"UMT5 XXL FP8 Scaled (Text Encoder, WAN 2.2)\": {\n",
        "        \"source\": \"huggingface\", \"repo_id\": \"Comfy-Org/Wan_2.2_ComfyUI_Repackaged\",\n",
        "        \"filename\": \"split_files/text_encoders/umt5_xxl_fp8_e4m3fn_scaled.safetensors\", \"subfolder\": \"models/clip\",\n",
        "        \"enabled\": download_umt5_encoder_22\n",
        "    },\n",
        "    \"UMT5 XXL Text Encoder (GGUF)\": {\n",
        "        \"source\": \"huggingface\", \"repo_id\": \"city96/umt5-xxl-encoder-gguf\",\n",
        "        \"filename\": \"umt5-xxl-encoder-Q4_K_M.gguf\", \"subfolder\": \"models/clip\",\n",
        "        \"enabled\": download_umt5_gguf_encoder\n",
        "    },\n",
        "    \"WAN 2.1 VAE\": {\n",
        "        \"source\": \"huggingface\", \"repo_id\": \"Comfy-Org/Wan_2.1_ComfyUI_repackaged\",\n",
        "        \"filename\": \"split_files/vae/wan_2.1_vae.safetensors\", \"subfolder\": \"models/vae\",\n",
        "        \"enabled\": download_wan_vae_21\n",
        "    },\n",
        "    \"WAN 2.1 VAE GGUF (1.3B VACE)\": {\n",
        "        \"source\": \"huggingface\", \"repo_id\": \"calcuis/wan-gguf\",\n",
        "        \"filename\": \"wan2.1-v1-vace-1.3b-q4_0.gguf\", \"subfolder\": \"models/vae\",\n",
        "        \"enabled\": download_wan_vae_gguf_14b_vace\n",
        "    },\n",
        "    \"WAN 2.2 VAE\": {\n",
        "        \"source\": \"huggingface\", \"repo_id\": \"Comfy-Org/Wan_2.2_ComfyUI_Repackaged\",\n",
        "        \"filename\": \"split_files/vae/wan2.2_vae.safetensors\", \"subfolder\": \"models/vae\",\n",
        "        \"enabled\": download_wan_vae_22\n",
        "    },\n",
        "\n",
        "    # LoRAs\n",
        "    \"Pusa V1 LoRA\": {\n",
        "        \"source\": \"huggingface\", \"repo_id\": \"Kijai/WanVideo_comfy\",\n",
        "        \"filename\": \"Pusa/Wan21_PusaV1_LoRA_14B_rank512_bf16.safetensors\", \"subfolder\": \"models/loras\",\n",
        "        \"enabled\": download_pusa_v1_lora\n",
        "    },\n",
        "    \"Lightx2v I2V LoRA (Rank 128)\": {\n",
        "        \"source\": \"huggingface\", \"repo_id\": \"Kijai/WanVideo_comfy\",\n",
        "        \"filename\": \"Lightx2v/lightx2v_I2V_14B_480p_cfg_step_distill_rank128_bf16.safetensors\", \"subfolder\": \"models/loras\",\n",
        "        \"enabled\": download_lightx2v_i2v_lora_rank128\n",
        "    },\n",
        "    \"Lightx2v T2V LoRA (14B, Rank 64)\": {\n",
        "        \"source\": \"huggingface\", \"repo_id\": \"Kijai/WanVideo_comfy\",\n",
        "        \"filename\": \"Lightx2v/lightx2v_T2V_14B_cfg_step_distill_v2_lora_rank64_bf16.safetensors\", \"subfolder\": \"models/loras\",\n",
        "        \"enabled\": download_lightx2v_t2v_lora_rank64\n",
        "    },\n",
        "    \"Lightx2v I2V LoRA (480p, Rank 64)\": {\n",
        "        \"source\": \"huggingface\", \"repo_id\": \"Kijai/WanVideo_comfy\",\n",
        "        \"filename\": \"Lightx2v/lightx2v_I2V_14B_480p_cfg_step_distill_rank64_bf16.safetensors\", \"subfolder\": \"models/loras\",\n",
        "        \"enabled\": download_lightx2v_i2v_480p_lora_rank64\n",
        "    },\n",
        "    \"Phantom-FusioniX LoRA\": {\n",
        "        \"source\": \"huggingface\", \"repo_id\": \"vrgamedevgirl84/Wan14BT2VFusioniX\",\n",
        "        \"filename\": \"FusionX_LoRa/Phantom_Wan_14B_FusionX_LoRA.safetensors\", \"subfolder\": \"models/loras\",\n",
        "        \"enabled\": download_phantom_fusionix_lora\n",
        "    },\n",
        "    \"Lightx2v T2V LoRA (14B, Rank 256)\": {\n",
        "        \"source\": \"huggingface\", \"repo_id\": \"Kijai/WanVideo_comfy\",\n",
        "        \"filename\": \"Lightx2v/lightx2v_T2V_14B_cfg_step_distill_v2_lora_rank256_bf16.safetensors\", \"subfolder\": \"models/loras\",\n",
        "        \"enabled\": download_lightx2v_t2v_lora_rank256\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "# --- Main Execution Logic ---\n",
        "print(\"🚀 Starting WAN Model Downloads...\")\n",
        "total_bytes_downloaded = 0\n",
        "\n",
        "for name, data in all_wan_assets.items():\n",
        "    if data['enabled']:\n",
        "        destination_folder = os.path.join(BASE_PATH, data['subfolder'])\n",
        "        os.makedirs(destination_folder, exist_ok=True)\n",
        "\n",
        "        if data['source'] == 'huggingface':\n",
        "            if not HF_TOKEN:\n",
        "                print(f\"❌ Hugging Face API token is missing. Please set HF_TOKEN. Skipping {name}.\")\n",
        "                continue\n",
        "\n",
        "            repo_id = data['repo_id']\n",
        "            file_name_in_repo = data['filename']\n",
        "            local_file_name = os.path.basename(file_name_in_repo) # Get just the filename for the local path\n",
        "            final_destination_path = os.path.join(destination_folder, local_file_name)\n",
        "\n",
        "            if not os.path.isfile(final_destination_path) or FORCE_DOWNLOAD_REFRESH:\n",
        "                display(Markdown(f\"\\n⬇️ Downloading **{name}** (`{local_file_name}`) → `{data['subfolder']}` (to {storage_type})…\"))\n",
        "                try:\n",
        "                    # hf_hub_download might create subdirectories based on `filename` if it includes paths\n",
        "                    # We download to a temporary cache and then move to ensure flat structure in `destination_folder`\n",
        "                    temp_download_path = hf_hub_download(\n",
        "                        repo_id=repo_id,\n",
        "                        filename=file_name_in_repo,\n",
        "                        cache_dir=os.path.join(LOCAL_BASE, \"hf_cache\"), # Use a dedicated cache\n",
        "                        local_dir_use_symlinks=False,\n",
        "                        token=HF_TOKEN,\n",
        "                        force_download=FORCE_DOWNLOAD_REFRESH\n",
        "                    )\n",
        "\n",
        "                    if os.path.exists(temp_download_path):\n",
        "                        # If a previous non-forced download exists at the final path, skip.\n",
        "                        if os.path.exists(final_destination_path) and not FORCE_DOWNLOAD_REFRESH:\n",
        "                            print(f\"ℹ️ \\033[90m{local_file_name}\\033[0m already exists in {storage_type} — skipping {name}.\")\n",
        "                            # Clean up the downloaded file from cache if it was already present at destination\n",
        "                            if os.path.exists(temp_download_path):\n",
        "                                os.remove(temp_download_path)\n",
        "                            continue\n",
        "\n",
        "                        shutil.copy(temp_download_path, final_destination_path)\n",
        "                        print(f\"✅ Completed {name}\")\n",
        "                        total_bytes_downloaded += os.path.getsize(final_destination_path)\n",
        "                        # Clean up the downloaded file from the temporary cache\n",
        "                        os.remove(temp_download_path)\n",
        "\n",
        "                    else:\n",
        "                        print(f\"❌ Failed to download {name}: File not found after Hugging Face download attempt.\")\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"❌ Failed to download {name}: {e}\")\n",
        "            else:\n",
        "                print(f\"ℹ️ \\033[90m{local_file_name}\\033[0m already exists in {storage_type} — skipping {name}.\")\n",
        "\n",
        "        elif data['source'] == 'civitai':\n",
        "            if not CIVITAI_API_KEY:\n",
        "                print(\"❌ Civitai API key is missing. Please set CIVITAI_API_KEY. Skipping Civitai downloads.\")\n",
        "                continue\n",
        "\n",
        "            model_id = extract_model_id(data['page_url'])\n",
        "            if not model_id:\n",
        "                print(f\"❌ Invalid Civitai URL for '{name}': {data['page_url']}\")\n",
        "                continue\n",
        "\n",
        "            model_info = fetch_model_data(model_id, CIVITAI_API_KEY)\n",
        "            if not model_info:\n",
        "                continue\n",
        "\n",
        "            version_id_match = re.search(r\"modelVersionId=(\\d+)\", data['page_url'])\n",
        "            target_version_id = int(version_id_match.group(1)) if version_id_match else None\n",
        "\n",
        "            target_version = None\n",
        "            if target_version_id:\n",
        "                for version in model_info.get('modelVersions', []):\n",
        "                    if version.get('id') == target_version_id:\n",
        "                        target_version = version\n",
        "                        break\n",
        "                if not target_version:\n",
        "                    print(f\"❌ Could not find model version ID {target_version_id} for '{name}'. Skipping download.\")\n",
        "                    continue\n",
        "            else:\n",
        "                if model_info.get('modelVersions'):\n",
        "                    target_version = model_info['modelVersions'][0] # Default to latest version\n",
        "                else:\n",
        "                    print(f\"❌ No model versions found for '{name}'. Skipping download.\")\n",
        "                    continue\n",
        "\n",
        "            files = target_version.get('files', [])\n",
        "            if not files:\n",
        "                print(f\"❌ No files found for the selected version of '{name}'. Skipping download.\")\n",
        "                continue\n",
        "\n",
        "            # Prioritize .safetensors, otherwise take the first file\n",
        "            best_file = next((f for f in files if '.safetensors' in f.get('name', '').lower()), files[0])\n",
        "            file_name = sanitize_filename(best_file.get('name', 'downloaded_file'))\n",
        "            download_url = best_file.get('downloadUrl')\n",
        "\n",
        "            if not download_url:\n",
        "                print(f\"❌ No download URL found for the best file for '{name}'. Skipping download.\")\n",
        "                continue\n",
        "\n",
        "            final_destination_path = Path(destination_folder) / file_name\n",
        "\n",
        "            if not final_destination_path.exists() or FORCE_DOWNLOAD_REFRESH:\n",
        "                display(Markdown(f\"\\n🚀 Downloading Civitai model: **[{model_info.get('name', name)}]({data['page_url']})**\"))\n",
        "                print(f\"   ↳ Saving as \\033[1m{file_name}\\033[0m to → `{data['subfolder']}` (in {storage_type})\")\n",
        "\n",
        "                downloaded_size = download_file_with_progress_util(download_url, final_destination_path, CIVITAI_API_KEY)\n",
        "                if downloaded_size > 0:\n",
        "                    print(f\"✅ Finished {name}\")\n",
        "                    total_bytes_downloaded += downloaded_size\n",
        "                else:\n",
        "                    print(f\"❌ Download failed for {name}\")\n",
        "            else:\n",
        "                print(f\"🔍 \\033[90m{file_name}\\033[0m already exists in {storage_type} — skipping {name}.\")\n",
        "    else:\n",
        "        print(f\"⏭️ Skipped: {name}\")\n",
        "\n",
        "if total_bytes_downloaded > 0:\n",
        "    total_gb = total_bytes_downloaded / (1024**3)\n",
        "    display(Markdown(f\"\\n--- \\n### 📊 Total Downloaded This Session: **{total_gb:.2f} GB**\"))\n",
        "\n",
        "print(\"\\n🎉 All selected WAN model downloads complete. Happy generating! 🎥✨\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "24acad2b"
      },
      "outputs": [],
      "source": [
        "# @title 📥 Download Models from Hugging Face (Optional)\n",
        "# @markdown This cell pulls essential ComfyUI models from Hugging Face into the correct location based on your storage setting.\n",
        "\n",
        "import os\n",
        "import requests\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "!pip install -q tqdm\n",
        "\n",
        "# --- Configuration ---\n",
        "LOCAL_BASE = '/content/ComfyUI' # Local temporary storage\n",
        "BASE_PATH = GDRIVE_BASE if SAVE_TO_GDRIVE else LOCAL_BASE\n",
        "\n",
        "# --- Model Selection ---\n",
        "# @markdown ---\n",
        "# @markdown ### **Checkpoints (Models):**\n",
        "# @markdown **Lumina VAE (ae.safetensors):** A 2B-parameter flow-based VAE for high-quality decoding, part of Lumina Image 2.0.\n",
        "download_lumina_vae = True  # @param {type:\"boolean\"}\n",
        "\n",
        "# @markdown **Flux CLIP-L (clip_l.safetensors):** The primary 246MB text-encoder for Flux pipelines (Apache-2.0).\n",
        "download_flux_clip_l = True  # @param {type:\"boolean\"}\n",
        "\n",
        "# @markdown **FLUX.1 Kontext Dev UNet (gguf):** A 12B-parameter rectified-flow UNet for text-driven image edits.\n",
        "download_flux_unet = False  # @param {type:\"boolean\"}\n",
        "\n",
        "# @markdown **T5XXL FP8 Encoder (safetensors):** A compact FP8-quantized T5XXL model for efficient text encoding.\n",
        "download_t5xxl_encoder = True  # @param {type:\"boolean\"}\n",
        "\n",
        "hf_models = {\n",
        "    \"Lumina VAE (ae.safetensors)\": {\n",
        "        \"url\": \"https://huggingface.co/Comfy-Org/Lumina_Image_2.0_Repackaged/resolve/main/split_files/vae/ae.safetensors\",\n",
        "        \"subfolder\": \"models/vae\",\n",
        "        \"fname\": \"ae.safetensors\"\n",
        "    },\n",
        "    \"Flux CLIP-L (clip_l.safetensors)\": {\n",
        "        \"url\": \"https://huggingface.co/comfyanonymous/flux_text_encoders/resolve/main/clip_l.safetensors\",\n",
        "        \"subfolder\": \"models/clip\",\n",
        "        \"fname\": \"clip_l.safetensors\"\n",
        "    },\n",
        "    \"FLUX.1 Kontext Dev UNet (gguf)\": {\n",
        "        \"url\": \"https://huggingface.co/bullerwins/FLUX.1-Kontext-dev-GGUF/resolve/main/flux1-kontext-dev-Q4_K_M.gguf\",\n",
        "        \"subfolder\": \"models/unet\",\n",
        "        \"fname\": \"flux1-kontext-dev-Q4_K_M.gguf\"\n",
        "    },\n",
        "    \"T5XXL FP8 Encoder (safetensors)\": {\n",
        "        \"url\": \"https://huggingface.co/comfyanonymous/flux_text_encoders/resolve/main/t5xxl_fp8_e4m3fn_scaled.safetensors\",\n",
        "        \"subfolder\": \"models/clip\",\n",
        "        \"fname\": \"t5xxl_fp8_e4m3fn_scaled.safetensors\"\n",
        "    },\n",
        "}\n",
        "\n",
        "selected_models = {\n",
        "    \"Lumina VAE (ae.safetensors)\": download_lumina_vae,\n",
        "    \"Flux CLIP-L (clip_l.safetensors)\": download_flux_clip_l,\n",
        "    \"FLUX.1 Kontext Dev UNet (gguf)\": download_flux_unet,\n",
        "    \"T5XXL FP8 Encoder (safetensors)\": download_t5xxl_encoder,\n",
        "}\n",
        "\n",
        "def download_with_progress(url, dest_path, token=None):\n",
        "    headers = {\"Authorization\": f\"Bearer {token}\"} if token else {}\n",
        "    with requests.get(url, headers=headers, stream=True) as r:\n",
        "        r.raise_for_status()\n",
        "        total = int(r.headers.get(\"content-length\", 0))\n",
        "        with open(dest_path, \"wb\") as f, tqdm(\n",
        "            total=total, unit=\"B\", unit_scale=True, desc=os.path.basename(dest_path)\n",
        "        ) as bar:\n",
        "            for chunk in r.iter_content(chunk_size=8192):\n",
        "                if chunk: f.write(chunk); bar.update(len(chunk))\n",
        "\n",
        "print(\"🚀 Starting Hugging Face model downloads...\")\n",
        "storage_type = \"Google Drive\" if SAVE_TO_GDRIVE else \"Colab Runtime\"\n",
        "for name, data in hf_models.items():\n",
        "    if selected_models.get(name, False):\n",
        "        folder = os.path.join(BASE_PATH, data['subfolder'])\n",
        "        dest = os.path.join(folder, data['fname'])\n",
        "        if not os.path.isfile(dest) or FORCE_MODEL_REFRESH:\n",
        "            print(f\"\\n⬇️ Downloading {data['fname']} → {data['subfolder']} (to {storage_type})…\")\n",
        "            try:\n",
        "                download_with_progress(data['url'], dest, token=HF_TOKEN)\n",
        "                print(f\"✅ Completed {data['fname']}\\n\")\n",
        "            except Exception as e:\n",
        "                print(f\"❌ Failed {data['fname']}: {e}\\n\")\n",
        "        else:\n",
        "            print(f\"ℹ️ {data['fname']} already exists in {storage_type}; skipping.\")\n",
        "    else:\n",
        "        print(f\"⏭️ Skipped: {name}\")\n",
        "\n",
        "print(\"🎉 All selected Hugging Face models are ready!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHQOYkv_IrUU"
      },
      "source": [
        "---\n",
        "\n",
        "## 📥 Download Models from Civitai\n",
        "<img src=\"https://shop.civitai.com/cdn/shop/files/kiss-cut-stickers-white-15x3.75-default-64c808ac640bf_2000x.png?v=1690831029\" width=\"200\">\n",
        "\n",
        "Download checkpoints and LoRAs from Civitai. The destination folder is determined by your storage settings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "c7fC8eCSSdDB"
      },
      "outputs": [],
      "source": [
        "# @title 📥 Civitai Downloader: Checkpoints & LoRAs (API-Driven)\n",
        "\n",
        "# @markdown Select the assets you want, and they will be downloaded to the correct folder. **Requires a valid Civitai API key.**\n",
        "\n",
        "import os\n",
        "import re\n",
        "import requests\n",
        "from tqdm.notebook import tqdm\n",
        "from pathlib import Path\n",
        "from typing import Optional, Dict, Any\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "# --- Configuration ---\n",
        "LOCAL_BASE = '/content/ComfyUI'\n",
        "# Check if running in a context where SAVE_TO_GDRIVE is defined, otherwise default to local\n",
        "SAVE_TO_GDRIVE_FLAG = 'GDRIVE_BASE' in locals() and 'SAVE_TO_GDRIVE' in locals() and SAVE_TO_GDRIVE\n",
        "BASE_PATH = GDRIVE_BASE if SAVE_TO_GDRIVE_FLAG else LOCAL_BASE\n",
        "storage_type = \"Google Drive\" if SAVE_TO_GDRIVE_FLAG else \"Colab Runtime\"\n",
        "\n",
        "# @markdown ---\n",
        "# @markdown **Force Re-download:**\n",
        "# @markdown If checked, all selected files below will be downloaded even if they already exist.\n",
        "FORCE_DOWNLOAD_REFRESH = False # @param {type:\"boolean\"}\n",
        "\n",
        "# @markdown ---\n",
        "# @markdown ### **👑 SFW Checkpoints**\n",
        "# @markdown **[CyberRealistic XL](https://civitai.com/models/312530/cyberrealistic-xl):** (Jul 2025) An ultra-clean, photo-realistic model for portraits, fashion, and editorial scenes.\n",
        "download_cyberrealistic = False # @param {type:\"boolean\"}\n",
        "# @markdown **[Juggernaut XL](https://civitai.com/models/133005/juggernaut-xl):** (Aug 2024) Highly popular and versatile for various SFW styles, including landscapes and architecture.\n",
        "download_juggernaut = False # @param {type:\"boolean\"}\n",
        "# @markdown **[epiCRealism XL](https://civitai.com/models/277058/epicrealism-xl):** (Sep 2024) Designed specifically for overall photorealism and detailed SFW images.\n",
        "download_epicrealism = False # @param {type:\"boolean\"}\n",
        "# @markdown **[Plant Milk Model Suite](https://civitai.com/models/1162518):** A versatile anime/illustrative model known for clean lines and vibrant colors.\n",
        "download_plant_milk = False # @param {type:\"boolean\"}\n",
        "# @markdown **[RI-Mix Pony Illustrious](https://civitai.com/models/996495):** A specialized Pony model for generating high-quality, illustrative anime-style art.\n",
        "download_ri_mix_pony = False # @param {type:\"boolean\"}\n",
        "\n",
        "# @markdown **[WAI-NSFW-illustrious-SDXL](https://civitai.com/models/827184/wai-nsfw-illustrious-sdxl):** (May 2025) Fine-tuned for high-quality, explicit NSFW content without needing LoRAs.\n",
        "download_wai_nsfw = False # @param {type:\"boolean\"}\n",
        "\n",
        "# @markdown ---\n",
        "# @markdown ### **🎨 SFW LoRAs**\n",
        "# @markdown **[Elden Ring XL Style](https://civitai.com/models/211082):** Captures the fantasy game style of Elden Ring, great for epic aesthetics.\n",
        "download_elden_ring_style = False # @param {type:\"boolean\"}\n",
        "# @markdown **[FameGrid XL](https://civitai.com/models/1368634):** (Jun 2025) For photorealistic social media style content.\n",
        "download_famegrid = False # @param {type:\"boolean\"}\n",
        "# @markdown **[Adjust Details & Photorealism](https://civitai.com/models/890914):** (Apr 2025) Versatile detailer to enhance realism in any image.\n",
        "download_adjust_details = False # @param {type:\"boolean\"}\n",
        "# @markdown **[Detailed Anime Style](https://civitai.com/models/402947):** (Mar 2025) Focuses on creating anime art with loose and voluminous hair.\n",
        "download_detailed_anime = False # @param {type:\"boolean\"}\n",
        "# @markdown **[New Fantasy Core](https://civitai.com/models/810000):** (Jan 2025) For dark fantasy styles, enhances magical and detailed scenes.\n",
        "download_new_fantasy = False # @param {type:\"boolean\"}\n",
        "# @markdown **[Beautiful Landscapes](https://civitai.com/models/448404):** Captures intricate landscape details with vibrant colors.\n",
        "download_beautiful_landscapes = False # @param {type:\"boolean\"}\n",
        "# @markdown **[Architecture SDXL](https://civitai.com/models/538977):** Trained on high-resolution images for urban and building art.\n",
        "download_architecture = False # @param {type:\"boolean\"}\n",
        "# @markdown **[Aesthetic Anime LoRA](https://civitai.com/models/295100):** Creates impressive anime aesthetics.\n",
        "download_aesthetic_anime = False # @param {type:\"boolean\"}\n",
        "# @markdown **[Popyay's Epic Fantasy Style](https://civitai.com/models/470073):** For epic fantasy art with dramatic scenes.\n",
        "download_popyay_fantasy = False # @param {type:\"boolean\"}\n",
        "# @markdown **[SDXL FaeTastic Details](https://civitai.com/models/134338):** Enhances images with magical fae-like details.\n",
        "download_faetastic_details = False # @param {type:\"boolean\"}\n",
        "# @markdown **[Plantra's Style Mix](https://civitai.com/models/1950544):** A style LoRA blending Incase and Rapscallion styles for stylized character art.\n",
        "download_plantra_lora = False # @param {type:\"boolean\"}\n",
        "\n",
        "# --- Asset Dictionary ---\n",
        "civitai_assets = {\n",
        "    # SFW Checkpoints\n",
        "    \"cyberrealistic_xl\": {\"page_url\": \"https://civitai.com/models/312530\", \"subfolder\": \"models/checkpoints\", \"enabled\": download_cyberrealistic},\n",
        "    \"juggernaut_xl\": {\"page_url\": \"https://civitai.com/models/133005\", \"subfolder\": \"models/checkpoints\", \"enabled\": download_juggernaut},\n",
        "    \"epicrealism_xl\": {\"page_url\": \"https://civitai.com/models/277058\", \"subfolder\": \"models/checkpoints\", \"enabled\": download_epicrealism},\n",
        "    \"plant_milk\": {\"page_url\": \"https://civitai.com/models/1162518\", \"subfolder\": \"models/checkpoints\", \"enabled\": download_plant_milk},\n",
        "    \"ri_mix_pony\": {\"page_url\": \"https://civitai.com/models/996495\", \"subfolder\": \"models/checkpoints\", \"enabled\": download_ri_mix_pony},\n",
        "    # NSFW Checkpoints (kept only WAI-NSFW)\n",
        "    \"wai_nsfw_illustrious\": {\"page_url\": \"https://civitai.com/models/827184\", \"subfolder\": \"models/checkpoints\", \"enabled\": download_wai_nsfw},\n",
        "    # SFW LoRAs\n",
        "    \"elden_ring_style\": {\"page_url\": \"https://civitai.com/models/211082\", \"subfolder\": \"models/loras\", \"enabled\": download_elden_ring_style},\n",
        "    \"famegrid_xl\": {\"page_url\": \"https://civitai.com/models/1368634\", \"subfolder\": \"models/loras\", \"enabled\": download_famegrid},\n",
        "    \"adjust_details\": {\"page_url\": \"https://civitai.com/models/890914\", \"subfolder\": \"models/loras\", \"enabled\": download_adjust_details},\n",
        "    \"detailed_anime\": {\"page_url\": \"https://civitai.com/models/402947\", \"subfolder\": \"models/loras\", \"enabled\": download_detailed_anime},\n",
        "    \"new_fantasy_core\": {\"page_url\": \"https://civitai.com/models/810000\", \"subfolder\": \"models/loras\", \"enabled\": download_new_fantasy},\n",
        "    \"beautiful_landscapes\": {\"page_url\": \"https://civitai.com/models/448404\", \"subfolder\": \"models/loras\", \"enabled\": download_beautiful_landscapes},\n",
        "    \"architecture_sdxl\": {\"page_url\": \"https://civitai.com/models/538977\", \"subfolder\": \"models/loras\", \"enabled\": download_architecture},\n",
        "    \"aesthetic_anime\": {\"page_url\": \"https://civitai.com/models/295100\", \"subfolder\": \"models/loras\", \"enabled\": download_aesthetic_anime},\n",
        "    \"popyay_fantasy\": {\"page_url\": \"https://civitai.com/models/470073\", \"subfolder\": \"models/loras\", \"enabled\": download_popyay_fantasy},\n",
        "    \"faetastic_details\": {\"page_url\": \"https://civitai.com/models/134338\", \"subfolder\": \"models/loras\", \"enabled\": download_faetastic_details},\n",
        "    \"plantra_lora\": {\"page_url\": \"https://civitai.com/models/1950544\", \"subfolder\": \"models/loras\", \"enabled\": download_plantra_lora},\n",
        "}\n",
        "\n",
        "# --- Robust Civitai Downloader Functions ---\n",
        "def extract_model_id(url: str) -> Optional[str]:\n",
        "    match = re.search(r\"models/(\\d+)\", url)\n",
        "    return match.group(1) if match else None\n",
        "\n",
        "def fetch_model_data(model_id: str, api_key: str) -> Optional[Dict[str, Any]]:\n",
        "    headers = {\"Authorization\": f\"Bearer {api_key}\"}\n",
        "    api_url = f\"https://civitai.com/api/v1/models/{model_id}\"\n",
        "    try:\n",
        "        response = requests.get(api_url, headers=headers)\n",
        "        response.raise_for_status()\n",
        "        return response.json()\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        # [THE FIX] Improved error message with a clickable link\n",
        "        model_page_url = f\"https://civitai.com/models/{model_id}\"\n",
        "        display(Markdown(f\"❌ **API Error:** Could not fetch metadata for model ID `{model_id}`. \"\n",
        "                         f\"Please check if the model exists and is accessible: [{model_page_url}]({model_page_url})\"))\n",
        "        print(f\"   (Underlying error: {e})\")\n",
        "        return None\n",
        "\n",
        "def sanitize_filename(name: str) -> str:\n",
        "    return re.sub(r'[\\\\/:\"*?<>|(){}[\\]]+', \"_\", name)\n",
        "\n",
        "def download_file_with_progress(url: str, output_path: Path, api_key: str) -> int:\n",
        "    headers = {\"Authorization\": f\"Bearer {api_key}\"}\n",
        "    total_downloaded = 0\n",
        "    try:\n",
        "        response = requests.get(url, headers=headers, stream=True)\n",
        "        response.raise_for_status()\n",
        "        total_size = int(response.headers.get(\"content-length\", 0))\n",
        "        with open(output_path, \"wb\") as file, tqdm(desc=output_path.name, total=total_size, unit='B', unit_scale=True, unit_divisor=1024) as bar:\n",
        "            for chunk in response.iter_content(chunk_size=8192):\n",
        "                size = file.write(chunk)\n",
        "                bar.update(size)\n",
        "        total_downloaded = output_path.stat().st_size\n",
        "        return total_downloaded\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Download failed for {output_path.name}: {e}\")\n",
        "        return 0\n",
        "\n",
        "# --- Main Execution Logic ---\n",
        "print(\"🚀 Starting Civitai Asset Downloader...\")\n",
        "if 'CIVITAI_API_KEY' not in locals() or not CIVITAI_API_KEY:\n",
        "    print(\"⚠️ Civitai API key not found or is empty. Skipping all Civitai downloads.\")\n",
        "else:\n",
        "    total_bytes_downloaded = 0\n",
        "    for asset_key, asset_data in civitai_assets.items():\n",
        "        if asset_data['enabled']:\n",
        "            model_id = extract_model_id(asset_data['page_url'])\n",
        "            if not model_id:\n",
        "                print(f\"❌ Invalid URL for '{asset_key}': {asset_data['page_url']}\")\n",
        "                continue\n",
        "\n",
        "            model_info = fetch_model_data(model_id, CIVITAI_API_KEY)\n",
        "            if not model_info:\n",
        "                continue\n",
        "\n",
        "            model_name_hyperlink = f\"**[{model_info['name']}]({asset_data['page_url']})**\"\n",
        "            latest_version = model_info['modelVersions'][0]\n",
        "            files = latest_version['files']\n",
        "            best_file = next((f for f in files if '.safetensors' in f['name'].lower()), files[0])\n",
        "            file_name = sanitize_filename(best_file['name'])\n",
        "            download_url = best_file['downloadUrl']\n",
        "\n",
        "            destination_folder = os.path.join(BASE_PATH, asset_data['subfolder'])\n",
        "            os.makedirs(destination_folder, exist_ok=True)\n",
        "            destination_path = Path(destination_folder) / file_name\n",
        "\n",
        "            if not destination_path.exists() or FORCE_DOWNLOAD_REFRESH:\n",
        "                display(Markdown(f\"\\n🚀 Downloading model: {model_name_hyperlink}\"))\n",
        "                print(f\"   ↳ Saving as \\033[1m{file_name}\\033[0m to → {asset_data['subfolder']} (in {storage_type})\")\n",
        "\n",
        "                downloaded_size = download_file_with_progress(download_url, destination_path, CIVITAI_API_KEY)\n",
        "                if downloaded_size > 0:\n",
        "                    total_bytes_downloaded += downloaded_size\n",
        "                    print(f\"✅ Finished\")\n",
        "            else:\n",
        "                print(f\"🔍 \\033[90m{file_name}\\033[0m already exists in {storage_type} — skipping.\")\n",
        "        else:\n",
        "            pass\n",
        "\n",
        "    if total_bytes_downloaded > 0:\n",
        "        total_gb = total_bytes_downloaded / (1024**3)\n",
        "        display(Markdown(f\"--- \\n### 📊 Total Downloaded This Session: **{total_gb:.2f} GB**\"))\n",
        "\n",
        "print(\"\\n🎉 Civitai download section complete.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5799b83a"
      },
      "source": [
        "---\n",
        "\n",
        "## 🔌 Install Custom Nodes\n",
        "\n",
        "Custom nodes are **always installed to your Google Drive** for persistence across sessions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ac220779"
      },
      "outputs": [],
      "source": [
        "# @title 🔌 Install Custom Nodes (Optional)\n",
        "# @markdown This cell installs essential and user-defined ComfyUI custom nodes to your Google Drive.\n",
        "# @markdown It features a real-time progress bar and automatically retries failed downloads.\n",
        "\n",
        "# @markdown ### **Mandatory Install**\n",
        "# @markdown **ComfyUI‑Manager** — Enhances the ComfyUI interface with a graphical hub to install, remove, enable, or disable nodes on the fly.\n",
        "\n",
        "# @markdown ---\n",
        "# @markdown ### **Optional Custom Nodes**\n",
        "# @markdown **ComfyUI‑Lora‑Manager:** Organize, preview, and apply LoRA models using an in-UI interface.\n",
        "install_lora_manager = True  # @param {type:\"boolean\"}\n",
        "# @markdown **ComfyUI‑Model‑Manager:** Browse, download, and delete checkpoints directly in ComfyUI.\n",
        "install_model_manager = True  # @param {type:\"boolean\"}\n",
        "# @markdown **ComfyUI‑Image‑Compressor:** Compress output images with control over quality and format.\n",
        "install_image_compressor = False # @param {type:\"boolean\"}\n",
        "# @markdown **ComfyUI‑Crystools:** Provides real-time stats, system monitors, and miscellaneous utility nodes.\n",
        "install_crystools = True  # @param {type:\"boolean\"}\n",
        "# @markdown **Civicomfy:** Search and download Civitai models straight from ComfyUI's interface.\n",
        "install_civicomfy = True  # @param {type:\"boolean\"}\n",
        "# @markdown **ComfyUI‑GGUF:** Adds GGUF format model support (optimized for quantized models).\n",
        "install_gguf = True  # @param {type:\"boolean\"}\n",
        "# @markdown **comfyui‑kjnodes:** Adds sage attention, custom samplers, and conditioning nodes.\n",
        "install_kjnodes = True  # @param {type:\"boolean\"}\n",
        "# @markdown **comfyui‑essentials:** File I/O, math, logic, and other vital scripting nodes.\n",
        "install_essentials = True  # @param {type:\"boolean\"}\n",
        "# @markdown **rgthree‑comfy:** Workflow boosters like load triggers, loop helpers, and param savers.\n",
        "install_rgthree = True  # @param {type:\"boolean\"}\n",
        "# @markdown **comfyui‑model‑downloader:** Adds drag-n-drop downloaders for Hugging Face and other platforms.\n",
        "install_model_downloader = False # @param {type:\"boolean\"}\n",
        "# @markdown **ComfyUI‑Dev‑Utils:** Debug and prototype faster with developer-focused tools and logging nodes.\n",
        "install_dev_utils = True # @param {type:\"boolean\"}\n",
        "# @markdown **Comfy-WaveSpeed:** Adds nodes for improving the image generation performance.\n",
        "install_wavespeed = False # @param {type:\"boolean\"}\n",
        "# @markdown **comfyui-universal-asset-downloader:** Adds a universal asset downloader node.\n",
        "install_asset_downloader = True # @param {type:\"boolean\"}\n",
        "# @markdown **ComfyUI-WanVideoWrapper:** Adds nodes for using WanVideo models.\n",
        "install_wanvideo_wrapper = True # @param {type:\"boolean\"}\n",
        "# @markdown **ComfyUI-MMAudio:** Adds nodes for integrating MMAudio audio generation with video.\n",
        "install_comfyui_mmaudio = True # @param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import subprocess\n",
        "import time\n",
        "import re\n",
        "import json\n",
        "from tqdm.notebook import tqdm\n",
        "from huggingface_hub import hf_hub_download # Import hf_hub_download for MMAudio models\n",
        "import sys # Import sys for pip installations\n",
        "\n",
        "# --- Global Configuration (Redefined for scope) ---\n",
        "LOCAL_BASE = '/content/ComfyUI' # Default local storage for Colab Runtime\n",
        "# Determines if models should be saved to Google Drive (if mounted and enabled) or Colab Runtime.\n",
        "# Ensure 'GDRIVE_BASE' and 'SAVE_TO_GDRIVE' variables are defined and set in a previous cell if you want to use Google Drive.\n",
        "SAVE_TO_GDRIVE_FLAG = 'GDRIVE_BASE' in locals() and 'SAVE_TO_GDRIVE' in locals() and SAVE_TO_GDRIVE\n",
        "BASE_PATH = GDRIVE_BASE if SAVE_TO_GDRIVE_FLAG else LOCAL_BASE\n",
        "storage_type = \"Google Drive\" if SAVE_TO_GDRIVE_FLAG else \"Colab Runtime\"\n",
        "\n",
        "# --- Robust Clone Function with Real-time Progress, Retries, and Cleanup ---\n",
        "def clone_with_progress_and_retry(name, url, path, retries=3, delay=5):\n",
        "    if os.path.exists(path):\n",
        "        print(f\"ℹ️ {name} already exists; skipping.\")\n",
        "        return True\n",
        "\n",
        "    for attempt in range(retries):\n",
        "        print(f\"⬇️ Cloning {name}... (Attempt {attempt + 1}/{retries})\")\n",
        "        try:\n",
        "            cmd = ['git', 'clone', '--progress', url, path]\n",
        "            process = subprocess.Popen(cmd, stderr=subprocess.PIPE, text=True, encoding='utf-8', errors='replace')\n",
        "\n",
        "            with tqdm(total=100, unit='%', desc=f\"Cloning {name}\") as bar:\n",
        "                last_percentage = 0\n",
        "                for line in process.stderr:\n",
        "                    match = re.search(r'Receiving objects:\\s+(\\d+)%', line)\n",
        "                    if not match:\n",
        "                        match = re.search(r'Resolving deltas:\\s+(\\d+)%', line)\n",
        "\n",
        "                    if match:\n",
        "                        percentage = int(match.group(1))\n",
        "                        increment = percentage - last_percentage\n",
        "                        if increment > 0:\n",
        "                            bar.update(increment)\n",
        "                            last_percentage = percentage\n",
        "\n",
        "                process.wait()\n",
        "\n",
        "                if process.returncode == 0:\n",
        "                    if bar.n < 100:\n",
        "                        bar.update(100 - bar.n)\n",
        "                    print(f\"\\n✅ {name} cloned successfully.\")\n",
        "                    return True\n",
        "                else:\n",
        "                    raise subprocess.CalledProcessError(process.returncode, cmd, stderr=process.stderr.read())\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Attempt {attempt + 1} failed for {name}.\")\n",
        "            if isinstance(e, subprocess.CalledProcessError) and e.stderr:\n",
        "                print(f\"   Git Error: {e.stderr.strip()}\")\n",
        "            else:\n",
        "                print(f\"   An unexpected error occurred: {e}\")\n",
        "\n",
        "            if os.path.exists(path):\n",
        "                print(f\"   Cleaning up failed directory: {path}\")\n",
        "                shutil.rmtree(path)\n",
        "\n",
        "            if attempt < retries - 1:\n",
        "                print(f\"   Retrying in {delay} seconds...\")\n",
        "                time.sleep(delay)\n",
        "\n",
        "    print(f\"❌❌ FAILED to clone {name} after {retries} attempts.\")\n",
        "    return False\n",
        "\n",
        "# --- Hugging Face Download Helper (for MMAudio Models) ---\n",
        "def download_hf_file(repo_id, filename, destination_folder, token=None, force_download=False):\n",
        "    \"\"\"Downloads a single file from Hugging Face with progress.\"\"\"\n",
        "    local_file_path = os.path.join(destination_folder, os.path.basename(filename))\n",
        "    if os.path.exists(local_file_path) and not force_download:\n",
        "        print(f\"ℹ️ {os.path.basename(filename)} already exists in {destination_folder}; skipping.\")\n",
        "        return True\n",
        "    try:\n",
        "        print(f\"⬇️ Downloading {filename} from {repo_id}...\")\n",
        "        hf_hub_download(\n",
        "            repo_id=repo_id,\n",
        "            filename=filename,\n",
        "            local_dir=destination_folder,\n",
        "            local_dir_use_symlinks=False,\n",
        "            token=token,\n",
        "            force_download=force_download,\n",
        "        )\n",
        "        print(f\"✅ Downloaded {filename}.\")\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Failed to download {filename}: {e}\")\n",
        "        return False\n",
        "\n",
        "\n",
        "# --- Node Installation Logic ---\n",
        "custom_nodes_dir = os.path.join(GDRIVE_BASE, \"custom_nodes/\")\n",
        "os.makedirs(custom_nodes_dir, exist_ok=True)\n",
        "\n",
        "print(\"--- Handling ComfyUI-Manager Installation ---\")\n",
        "manager_dir = os.path.join(custom_nodes_dir, \"ComfyUI-Manager\")\n",
        "manager_url = \"https://github.com/ltdrdata/ComfyUI-Manager.git\"\n",
        "if os.path.exists(manager_dir):\n",
        "    print(\"Removing existing ComfyUI-Manager directory to ensure a fresh install...\")\n",
        "    shutil.rmtree(manager_dir)\n",
        "clone_with_progress_and_retry(\"ComfyUI-Manager\", manager_url, manager_dir)\n",
        "\n",
        "\n",
        "nodes_to_install = {\n",
        "    \"ComfyUI-Lora-Manager\":      \"https://github.com/willmiao/ComfyUI-Lora-Manager.git\",\n",
        "    \"ComfyUI-Model-Manager\":     \"https://github.com/hayden-fr/ComfyUI-Model-Manager.git\",\n",
        "    \"ComfyUI-Image-Compressor\":  \"https://github.com/liuqianhonga/ComfyUI-Image-Compressor.git\",\n",
        "    \"ComfyUI-Crystools\":         \"https://github.com/crystian/ComfyUI-Crystools.git\",\n",
        "    \"Civicomfy\":                 \"https://github.com/MoonGoblinDev/Civicomfy.git\",\n",
        "    \"ComfyUI-GGUF\":              \"https://github.com/city96/ComfyUI-GGUF.git\",\n",
        "    \"comfyui-kjnodes\":           \"https://github.com/kijai/comfyui-kjnodes.git\",\n",
        "    \"comfyui-essentials\":        \"https://github.com/cubiq/comfyui_essentials.git\",\n",
        "    \"rgthree-comfy\":             \"https://github.com/rgthree/rgthree-comfy.git\",\n",
        "    \"comfyui-model-downloader\":  \"https://github.com/ciri/comfyui-model-downloader.git\",\n",
        "    \"ComfyUI-Dev-Utils\":         \"https://github.com/ty0x2333/ComfyUI-Dev-Utils\",\n",
        "    \"Comfy-WaveSpeed\":           \"https://github.com/chengzeyi/Comfy-WaveSpeed.git\",\n",
        "    \"comfyui-universal-asset-downloader\": \"https://github.com/thaakeno/comfyui-universal-asset-downloader.git\",\n",
        "    \"ComfyUI-WanVideoWrapper\":   \"https://github.com/kijai/ComfyUI-WanVideoWrapper.git\",\n",
        "    \"ComfyUI-MMAudio\":           \"https://github.com/kijai/ComfyUI-MMAudio.git\", # Added MMAudio\n",
        "}\n",
        "\n",
        "selected_nodes = {\n",
        "    \"ComfyUI-Lora-Manager\":     install_lora_manager,\n",
        "    \"ComfyUI-Model-Manager\":    install_model_manager,\n",
        "    \"ComfyUI-Image-Compressor\": install_image_compressor,\n",
        "    \"ComfyUI-Crystools\":        install_crystools,\n",
        "    \"Civicomfy\":                install_civicomfy,\n",
        "    \"ComfyUI-GGUF\":             install_gguf,\n",
        "    \"comfyui-kjnodes\":          install_kjnodes,\n",
        "    \"comfyui-essentials\":       install_essentials,\n",
        "    \"rgthree-comfy\":            install_rgthree,\n",
        "    \"comfyui-model-downloader\": install_model_downloader,\n",
        "    \"ComfyUI-Dev-Utils\":        install_dev_utils,\n",
        "    \"Comfy-WaveSpeed\":          install_wavespeed,\n",
        "    \"comfyui-universal-asset-downloader\": install_asset_downloader,\n",
        "    \"ComfyUI-WanVideoWrapper\":  install_wanvideo_wrapper,\n",
        "    \"ComfyUI-MMAudio\":          install_comfyui_mmaudio, # Added MMAudio selection\n",
        "}\n",
        "\n",
        "print(\"\\n--- [FIX] Pre-installing all known Custom Node dependencies ---\")\n",
        "!pip install piexif deepdiff --upgrade gguf --quiet\n",
        "!pip install aiohttp-sse --quiet\n",
        "!pip install ftfy markdownify pycryptodome \"dghs-imgutils[gpu]\" --quiet\n",
        "!pip install huggingface-hub --quiet # Ensure huggingface_hub is installed for MMAudio model download\n",
        "!pip install torchdiffeq --quiet # Install the missing dependency for MMAudio\n",
        "print(\"✅ All known dependencies have been pre-installed.\")\n",
        "\n",
        "\n",
        "print(\"\\n--- Cloning other selected custom nodes into Google Drive ---\")\n",
        "for name, repo in nodes_to_install.items():\n",
        "    # Ensure FORCE_DOWNLOAD_REFRESH is defined here within the loop's scope\n",
        "    if 'FORCE_DOWNLOAD_REFRESH' not in globals():\n",
        "         FORCE_DOWNLOAD_REFRESH = False # Default to False if not defined elsewhere\n",
        "\n",
        "    if selected_nodes.get(name, False):\n",
        "        path = os.path.join(custom_nodes_dir, name)\n",
        "        clone_with_progress_and_retry(name, repo, path)\n",
        "\n",
        "        # --- MMAudio Specific Model Download ---\n",
        "        if name == \"ComfyUI-MMAudio\":\n",
        "            print(\"\\n--- Downloading required models for ComfyUI-MMAudio ---\")\n",
        "            # MMAudio models go into ComfyUI/models/mmaudio\n",
        "            mmaudio_model_dir = os.path.join(BASE_PATH, \"models\", \"mmaudio\")\n",
        "            os.makedirs(mmaudio_model_dir, exist_ok=True)\n",
        "\n",
        "            # Download MMAudio safetensors (the VAE)\n",
        "            download_hf_file(\n",
        "                repo_id=\"Kijai/MMAudio_safetensors\",\n",
        "                filename=\"mmaudio_vae_44k_fp32.safetensors\", # Corrected filename\n",
        "                destination_folder=mmaudio_model_dir,\n",
        "                token=HF_TOKEN,\n",
        "                force_download=FORCE_DOWNLOAD_REFRESH # Reuse global refresh setting\n",
        "            )\n",
        "             # Download the main MMAudio safetensors\n",
        "            download_hf_file(\n",
        "                repo_id=\"Kijai/MMAudio_safetensors\",\n",
        "                filename=\"mmaudio_large_44k_v2_fp32.safetensors\", # Corrected filename\n",
        "                destination_folder=mmaudio_model_dir,\n",
        "                token=HF_TOKEN,\n",
        "                force_download=FORCE_DOWNLOAD_REFRESH # Reuse global refresh setting\n",
        "            )\n",
        "\n",
        "            # Download additional MMAudio safetensors\n",
        "            download_hf_file(\n",
        "                repo_id=\"Kijai/MMAudio_safetensors\",\n",
        "                filename=\"apple_DFN5B-CLIP-ViT-H-14-384_fp32.safetensors\",\n",
        "                destination_folder=mmaudio_model_dir,\n",
        "                token=HF_TOKEN,\n",
        "                force_download=FORCE_DOWNLOAD_REFRESH\n",
        "            )\n",
        "            download_hf_file(\n",
        "                repo_id=\"Kijai/MMAudio_safetensors\",\n",
        "                filename=\"mmaudio_synchformer_fp32.safetensors\",\n",
        "                destination_folder=mmaudio_model_dir,\n",
        "                token=HF_TOKEN,\n",
        "                force_download=FORCE_DOWNLOAD_REFRESH\n",
        "            )\n",
        "\n",
        "            # Download Nvidia bigvganv2 (used with 44k mode)\n",
        "            # The path structure in the MMAudio repo suggests a nested path under mmaudio/nvidia\n",
        "            bigvgan_dest_dir = os.path.join(mmaudio_model_dir, \"nvidia\", \"bigvgan_v2_44khz_128band_512x\")\n",
        "            os.makedirs(bigvgan_dest_dir, exist_ok=True)\n",
        "\n",
        "            # Download config.json and generator.pt from nvidia/bigvgan_v2_44khz_128band_512x\n",
        "            download_hf_file(\n",
        "                 repo_id=\"nvidia/bigvgan_v2_44khz_128band_512x\",\n",
        "                 filename=\"config.json\",\n",
        "                 destination_folder=bigvgan_dest_dir,\n",
        "                 token=HF_TOKEN,\n",
        "                 force_download=FORCE_DOWNLOAD_REFRESH\n",
        "            )\n",
        "            download_hf_file(\n",
        "                 repo_id=\"nvidia/bigvgan_v2_44khz_128band_512x\",\n",
        "                 filename=\"bigvgan_generator.pt\", # Corrected filename\n",
        "                 destination_folder=bigvgan_dest_dir,\n",
        "                 token=HF_TOKEN,\n",
        "                 force_download=FORCE_DOWNLOAD_REFRESH\n",
        "            )\n",
        "            print(\"✅ MMAudio required models download attempt complete.\")\n",
        "        # --- End MMAudio Specific Logic ---\n",
        "\n",
        "    else:\n",
        "        print(f\"⏭️ Skipped {name}\")\n",
        "\n",
        "# [FIX] Disable Crystools' automatic installer to prevent re-downloads\n",
        "# Ensure Crystools is installed before trying to configure it\n",
        "if selected_nodes.get(\"ComfyUI-Crystools\", False):\n",
        "    print(\"\\n--- Configuring Crystools to disable automatic dependency installation ---\")\n",
        "    crystools_config_path = os.path.join(custom_nodes_dir, \"ComfyUI-Crystools/crystools.json\")\n",
        "    crystools_config = {\"install_dependencies\": False}\n",
        "    try:\n",
        "        # Ensure the directory exists\n",
        "        os.makedirs(os.path.dirname(crystools_config_path), exist_ok=True)\n",
        "        with open(crystools_config_path, 'w') as f:\n",
        "            json.dump(crystools_config, f)\n",
        "        print(\"✅ Crystools configuration updated.\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Failed to write Crystools config: {e}\")\n",
        "else:\n",
        "    print(\"⏭️ Skipped Crystools configuration (Crystools not selected for install).\")\n",
        "\n",
        "\n",
        "# This step is crucial for compatibility with some older nodes\n",
        "# Check if numpy is installed first, then force-reinstall the specific version\n",
        "try:\n",
        "    import numpy\n",
        "    print(\"\\n--- Enforcing numpy version for compatibility ---\")\n",
        "    get_ipython().system('pip install numpy==1.26.4 --force-reinstall --quiet')\n",
        "    print(\"✅ Enforced numpy version 1.26.4.\")\n",
        "except ImportError:\n",
        "    print(\"\\n--- Installing numpy version for compatibility ---\")\n",
        "    get_ipython().system('pip install numpy==1.26.4 --quiet')\n",
        "    print(\"✅ Installed numpy version 1.26.4.\")\n",
        "\n",
        "\n",
        "print(\"\\n🎉 All custom node installations complete.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "DbatX9ApTPWg"
      },
      "outputs": [],
      "source": [
        "# @title 🔎 Verify Installed Models and LoRAs\n",
        "# @markdown This cell scans all configured locations and lists the detected models and LoRAs.\n",
        "\n",
        "import os\n",
        "\n",
        "GDRIVE_MODEL_BASE = GDRIVE_BASE\n",
        "LOCAL_BASE = '/content/ComfyUI'\n",
        "\n",
        "if SAVE_TO_GDRIVE:\n",
        "    print(\"💾 Scanning Google Drive for all models.\")\n",
        "    checkpoint_paths = [os.path.join(GDRIVE_MODEL_BASE, \"models/checkpoints\")]\n",
        "    lora_paths = [os.path.join(GDRIVE_MODEL_BASE, \"models/loras\")]\n",
        "else:\n",
        "    print(\"☁️ Scanning Colab runtime for models.\")\n",
        "    checkpoint_paths = [os.path.join(LOCAL_BASE, \"models/checkpoints\")]\n",
        "    lora_paths = [os.path.join(LOCAL_BASE, \"models/loras\")]\n",
        "\n",
        "def scan_directory(paths, title, extensions):\n",
        "    print(f\"--- 🔍 Checking {title} ---\")\n",
        "    found_files = set()\n",
        "    for path in paths:\n",
        "        print(f\"   Scanning: {path}\")\n",
        "        if os.path.exists(path):\n",
        "            for f in os.listdir(path):\n",
        "                if f.endswith(extensions):\n",
        "                    found_files.add(f)\n",
        "        else: print(\"   ...Directory not found.\")\n",
        "\n",
        "    if found_files:\n",
        "        for item in sorted(list(found_files)):\n",
        "            print(f\"✅ {item}\")\n",
        "    else: print(f\"   No {title.lower()} found in the scanned directories.\")\n",
        "    print(\"\\n\")\n",
        "\n",
        "scan_directory(checkpoint_paths, \"Checkpoints\", ('.safetensors', '.ckpt', '.pth'))\n",
        "scan_directory(lora_paths, \"LoRAs\", ('.safetensors', '.ckpt', '.pth'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4641a00"
      },
      "source": [
        "---\n",
        "\n",
        "## 🌐 Setup Ngrok for Public Access\n",
        "\n",
        "Set up Ngrok to create a public URL, allowing you to access the ComfyUI web interface from any browser."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ab2c5f18"
      },
      "outputs": [],
      "source": [
        "# @title Setup and Authenticate Ngrok\n",
        "# @markdown This cell downloads, extracts, and authenticates Ngrok using your authtoken.\n",
        "\n",
        "import os\n",
        "\n",
        "%cd /content\n",
        "\n",
        "print(\"Cleaning up old ngrok files...\")\n",
        "!rm -f ngrok ngrok.zip ngrok-stable-linux-amd64.tgz\n",
        "print(\"✅ Cleaned up old ngrok files.\")\n",
        "\n",
        "print(\"\\nDownloading ngrok...\")\n",
        "!wget -O ngrok-stable-linux-amd64.tgz https://bin.equinox.io/c/bNyj1mQVY4c/ngrok-v3-stable-linux-amd64.tgz\n",
        "!tar -xvzf ngrok-stable-linux-amd64.tgz\n",
        "!chmod +x ngrok\n",
        "print(\"✅ Downloaded and set up ngrok.\")\n",
        "\n",
        "if NGROK_AUTHTOKEN:\n",
        "    print(\"\\nAuthenticating ngrok...\")\n",
        "    get_ipython().system(f'./ngrok authtoken \"{NGROK_AUTHTOKEN}\"')\n",
        "    print(\"✅ Ngrok authenticated.\")\n",
        "else:\n",
        "    print(\"\\n⚠️ Ngrok authtoken not provided. Public URL will not be available.\")\n",
        "\n",
        "print(\"\\n🎉 Ngrok setup complete.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dea67d4a"
      },
      "source": [
        "---\n",
        "\n",
        "## ▶️ Launch ComfyUI\n",
        "\n",
        "Finally, launch the ComfyUI server. Once the server starts, you can access the web interface via the Ngrok public URL."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "2FVGUeIgCv63"
      },
      "outputs": [],
      "source": [
        "# @title 🚀 ComfyUI Launch\n",
        "# @markdown This cell launches ComfyUI using the Ngrok public URL.\n",
        "\n",
        "import subprocess\n",
        "import threading\n",
        "import time\n",
        "import requests\n",
        "import os\n",
        "import re\n",
        "import psutil\n",
        "import shutil\n",
        "import yaml\n",
        "from datetime import datetime, timedelta\n",
        "from IPython.display import display, HTML, Javascript, clear_output\n",
        "import json\n",
        "\n",
        "# --- Global State & Configuration ---\n",
        "# This dictionary holds the real-time state of the UI and system.\n",
        "status_info = {\n",
        "    'step': 'Initializing',\n",
        "    'progress': 0,\n",
        "    'local_url': 'Pending...',\n",
        "    'public_url': 'Pending...',\n",
        "    'ready': False, # True when ComfyUI server is detected as running\n",
        "    'start_time': datetime.now(),\n",
        "    'setup_time': '00:00:00',\n",
        "    'server_start_time': None,\n",
        "    'system_info': {\n",
        "        'cpu_usage': 0, 'ram_used_gb': 0, 'ram_total_gb': 0,\n",
        "        'gpu_available': False, 'gpu_name': 'N/A', 'gpu_util_pct': 0,\n",
        "        'vram_used_gb': 0, 'vram_total_gb': 0,\n",
        "        'disk_used_gb': 0, 'disk_total_gb': 0,\n",
        "    },\n",
        "    'download_status': {'active': False, 'filename': 'N/A', 'progress': 0, 'speed': 'N/A'},\n",
        "    'ui_rendered': False # Flag to ensure initial HTML is rendered only once\n",
        "}\n",
        "\n",
        "# --- High-Quality SVG Icons ---\n",
        "# A curated set of icons for the UI.\n",
        "ICONS = {\n",
        "    \"link\": \"\"\"<svg xmlns=\"http://www.w3.org/2000/svg\" width=\"20\" height=\"20\" viewBox=\"0 0 24 24\" fill=\"none\" stroke=\"currentColor\" stroke-width=\"2\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.72\"/><path d=\"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.72-1.72\"/></svg>\"\"\",\n",
        "    \"globe\": \"\"\"<svg xmlns=\"http://www.w3.org/2000/svg\" width=\"20\" height=\"20\" viewBox=\"0 0 24 24\" fill=\"none\" stroke=\"currentColor\" stroke-width=\"2\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><circle cx=\"12\" cy=\"12\" r=\"10\"/><path d=\"M12 2a14.5 14.5 0 0 0 0 20 14.5 14.5 0 0 0 0-20Z\"/><path d=\"M2 12h20\"/></svg>\"\"\",\n",
        "    \"gpu\": \"\"\"<svg xmlns=\"http://www.w3.org/2000/svg\" width=\"20\" height=\"20\" viewBox=\"0 0 24 24\" fill=\"none\" stroke=\"currentColor\" stroke-width=\"2\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><rect width=\"18\" height=\"18\" x=\"3\" y=\"3\" rx=\"2\"/><path d=\"M8 8h.01\"/><path d=\"M12 8h.01\"/><path d=\"M16 8h.01\"/><path d=\"M8 12h.01\"/><path d=\"M12 12h.01\"/><path d=\"M16 12h.01\"/><path d=\"M8 16h.01\"/><path d=\"M12 16h.01\"/><path d=\"M16 16h.01\"/></svg>\"\"\",\n",
        "    \"cpu\": \"\"\"<svg xmlns=\"http://www.w3.org/2000/svg\" width=\"20\" height=\"20\" viewBox=\"0 0 24 24\" fill=\"none\" stroke=\"currentColor\" stroke-width=\"2\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><rect width=\"16\" height=\"16\" x=\"4\" y=\"4\" rx=\"2\"/><path d=\"M9 9h6v6H9z\"/><path d=\"M15 2v2\"/><path d=\"M15 20v2\"/><path d=\"M9 2v2\"/><path d=\"M9 20v2\"/><path d=\"M2 9h2\"/><path d=\"M2 15h2\"/><path d=\"M20 9h2\"/><path d=\"M20 15h2\"/></svg>\"\"\",\n",
        "    \"disk\": \"\"\"<svg xmlns=\"http://www.w3.org/2000/svg\" width=\"20\" height=\"20\" viewBox=\"0 0 24 24\" fill=\"none\" stroke=\"currentColor\" stroke-width=\"2\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M12 22c5.523 0 10-4.477 10-10S17.523 2 12 2 2 6.477 2 12s4.477 10 10 10Z\"/><path d=\"M12 16a4 4 0 1 0 0-8 4 4 0 0 0 0 8Z\"/><path d=\"M12 12v10\"/></svg>\"\"\",\n",
        "    \"log\": \"\"\"<svg xmlns=\"http://www.w3.org/2000/svg\" width=\"20\" height=\"20\" viewBox=\"0 0 24 24\" fill=\"none\" stroke=\"currentColor\" stroke-width=\"2\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M16 22h2a2 2 0 0 0 2-2V7l-5-5H6a2 2 0 0 0-2 2v3\"/><path d=\"M14 2v4a2 2 0 0 0 2 2h4\"/><path d=\"M4 12a1 1 0 0 1 1-1h1a1 1 0 0 1 1 1v6a1 1 0 0 1-1 1H5a1 1 0 0 1-1-1Z\"/><path d=\"M9 12a1 1 0 0 1 1-1h1a1 1 0 0 1 1 1v6a1 1 0 0 1-1 1h-1a1 1 0 0 1-1-1Z\"/></svg>\"\"\",\n",
        "    \"timer\": \"\"\"<svg xmlns=\"http://www.w3.org/2000/svg\" width=\"20\" height=\"20\" viewBox=\"0 0 24 24\" fill=\"none\" stroke=\"currentColor\" stroke-width=\"2\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><circle cx=\"12\" cy=\"12\" r=\"10\"/><polyline points=\"12 6 12 12 16 14\"/></svg>\"\"\",\n",
        "    \"download\": \"\"\"<svg xmlns=\"http://www.w3.org/2000/svg\" width=\"20\" height=\"20\" viewBox=\"0 0 24 24\" fill=\"none\" stroke=\"currentColor\" stroke-width=\"2\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M21 15v4a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2v-4\"/><polyline points=\"7 10 12 15 17 10\"/><line x1=\"12\" y1=\"15\" x2=\"12\" y2=\"3\"/></svg>\"\"\",\n",
        "    \"ready\": \"\"\"<svg xmlns=\"http://www.w3.org/2000/svg\" width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"currentColor\"><path d=\"M12 2C6.48 2 2 6.48 2 12s4.48 10 10 10 10-4.48 10-10S17.52 2 12 2zm-2 15l-5-5 1.41-1.41L10 14.17l7.59-7.59L19 8l-9 9z\"/></svg>\"\"\",\n",
        "}\n",
        "\n",
        "# --- System & UI Utilities ---\n",
        "def get_system_info():\n",
        "    \"\"\"Gathers real-time system information (CPU, RAM, Disk, GPU).\"\"\"\n",
        "    si = status_info['system_info']\n",
        "    try:\n",
        "        si['cpu_usage'] = psutil.cpu_percent(interval=None)\n",
        "        ram = psutil.virtual_memory()\n",
        "        si['ram_used_gb'] = ram.used / (1024**3)\n",
        "        si['ram_total_gb'] = ram.total / (1024**3)\n",
        "        disk_total, disk_used, _ = shutil.disk_usage('/')\n",
        "        si['disk_used_gb'] = disk_used / (1024**3)\n",
        "        si['disk_total_gb'] = disk_total / (1024**3)\n",
        "        if os.path.exists('/usr/bin/nvidia-smi'):\n",
        "            smi_output = subprocess.run(['nvidia-smi', '--query-gpu=name,utilization.gpu,memory.used,memory.total', '--format=csv,noheader,nounits'], capture_output=True, text=True).stdout.strip()\n",
        "            if smi_output:\n",
        "                name, util, vram_used, vram_total = smi_output.split(', ')\n",
        "                si.update({'gpu_available': True, 'gpu_name': name, 'gpu_util_pct': int(util), 'vram_used_gb': int(vram_used) / 1024, 'vram_total_gb': int(vram_total) / 1024})\n",
        "    except Exception: pass\n",
        "\n",
        "def add_log_to_widget(message, level='info'):\n",
        "    \"\"\"Sends a JavaScript command to append a log entry to the UI, respecting filters.\"\"\"\n",
        "    log_entry = {'timestamp': datetime.now().strftime('%H:%M:%S'), 'message': message, 'level': level}\n",
        "    escaped_message = json.dumps(log_entry['message'])\n",
        "    js_command = f\"\"\"\n",
        "    (() => {{\n",
        "        const logContainer = document.getElementById('cc-log-entries-container');\n",
        "        if (!logContainer) return;\n",
        "        const wasAtBottom = logContainer.scrollHeight - logContainer.scrollTop - logContainer.clientHeight < 20;\n",
        "        const newLog = document.createElement('div');\n",
        "        newLog.className = 'cc-log-entry';\n",
        "        newLog.dataset.level = '{log_entry['level']}';\n",
        "        newLog.innerHTML = `<div class=\"cc-log-gutter cc-log-{log_entry['level']}\"></div><div class=\"cc-log-content\"><span class=\"cc-log-time\">{log_entry['timestamp']}</span> <span class=\"cc-log-message\">${{{escaped_message}}}</span></div>`;\n",
        "        const isVisible = document.getElementById('log-filter-{log_entry['level']}').checked;\n",
        "        if (!isVisible) {{ newLog.style.display = 'none'; }}\n",
        "        logContainer.appendChild(newLog);\n",
        "        if (wasAtBottom) {{ logContainer.scrollTop = logContainer.scrollHeight; }}\n",
        "    }})();\n",
        "    \"\"\"\n",
        "    display(Javascript(js_command))\n",
        "\n",
        "def update_status(**kwargs):\n",
        "    \"\"\"Updates the global status and triggers a UI refresh.\"\"\"\n",
        "    status_info.update(kwargs)\n",
        "    if not status_info['ui_rendered']:\n",
        "        render_initial_html()\n",
        "        status_info['ui_rendered'] = True\n",
        "    else:\n",
        "        generate_update_script()\n",
        "\n",
        "def generate_update_script():\n",
        "    \"\"\"Generates and executes a JavaScript snippet to update all dynamic UI elements.\"\"\"\n",
        "    get_system_info()\n",
        "    si = status_info['system_info']\n",
        "\n",
        "    if status_info['ready']:\n",
        "        elapsed_time = status_info['setup_time']\n",
        "        comfyui_uptime = str(timedelta(seconds=int((datetime.now() - status_info['server_start_time']).total_seconds()))).split('.')[0]\n",
        "    else:\n",
        "        elapsed_time = str(timedelta(seconds=int((datetime.now() - status_info['start_time']).total_seconds()))).split('.')[0]\n",
        "        comfyui_uptime = \"Offline\"\n",
        "\n",
        "    status_text_anim = \"System Online & Ready\" if status_info['ready'] else status_info['step']\n",
        "    js_commands = [\n",
        "        f\"document.getElementById('cc-status-text').innerText = '{status_text_anim}';\",\n",
        "        f\"document.getElementById('cc-main-progress-bar-fill').style.width = '{status_info['progress']}%';\",\n",
        "        f\"document.getElementById('cc-main-progress-bar-shine').style.left = '{status_info['progress'] - 10}%';\",\n",
        "        f\"document.body.classList.toggle('system-ready', {str(status_info['ready']).lower()});\",\n",
        "        f\"document.getElementById('cc-local-url-button').href = '{status_info['local_url'] if status_info['ready'] else '#'}';\",\n",
        "        f\"document.getElementById('cc-local-url-button').classList.toggle('disabled', {str(not status_info['ready']).lower()});\",\n",
        "        f\"document.getElementById('cc-public-url-button').href = '{status_info['public_url'] if 'http' in status_info['public_url'] else '#'}';\",\n",
        "        f\"document.getElementById('cc-public-url-button').classList.toggle('disabled', {str('http' not in status_info['public_url']).lower()});\",\n",
        "        f\"document.getElementById('cc-gpu-name').innerText = '{si['gpu_name'] if si['gpu_available'] else 'GPU N/A'}';\",\n",
        "        f\"document.getElementById('cc-vram-bar-fill').style.width = '{(si['vram_used_gb'] / si['vram_total_gb'] * 100) if si.get('vram_total_gb', 0) > 0 else 0}%';\",\n",
        "        f\"document.getElementById('cc-vram-text').innerText = `{si.get('vram_used_gb', 0):.1f}/{si.get('vram_total_gb', 0):.1f} GB`;\",\n",
        "        f\"document.getElementById('cc-gpu-util-bar-fill').style.width = '{si.get('gpu_util_pct', 0)}%';\",\n",
        "        f\"document.getElementById('cc-gpu-util-text').innerText = `{si.get('gpu_util_pct', 0)}%`;\",\n",
        "        f\"document.getElementById('cc-ram-bar-fill').style.width = '{(si['ram_used_gb'] / si['ram_total_gb'] * 100) if si['ram_total_gb'] > 0 else 0}%';\",\n",
        "        f\"document.getElementById('cc-ram-text').innerText = `{si['ram_used_gb']:.1f}/{si['ram_total_gb']:.1f} GB`;\",\n",
        "        f\"document.getElementById('cc-cpu-usage-bar-fill').style.width = '{si['cpu_usage']}%';\",\n",
        "        f\"document.getElementById('cc-cpu-usage-text').innerText = `{si['cpu_usage']:.1f}%`;\",\n",
        "        f\"document.getElementById('cc-disk-bar-fill').style.width = '{(si['disk_used_gb'] / si['disk_total_gb'] * 100) if si['disk_total_gb'] > 0 else 0}%';\",\n",
        "        f\"document.getElementById('cc-disk-text').innerText = `{si['disk_used_gb']:.1f}/{si['disk_total_gb']:.1f} GB`;\",\n",
        "        f\"document.getElementById('cc-setup-time-value').innerText = '{elapsed_time}';\",\n",
        "        f\"document.getElementById('cc-uptime-value').innerText = '{comfyui_uptime}';\",\n",
        "    ]\n",
        "    if status_info['ready']:\n",
        "        js_commands.append(\"document.getElementById('cc-status-loader').style.display = 'none';\")\n",
        "        js_commands.append(f\"document.getElementById('cc-status-icon-ready').style.display = 'block';\")\n",
        "\n",
        "    ds = status_info['download_status']\n",
        "    js_commands.append(f\"document.getElementById('cc-download-monitor').style.display = '{'grid' if ds['active'] else 'none'}';\")\n",
        "    if ds['active']:\n",
        "        js_commands.extend([\n",
        "            f\"document.getElementById('cc-dl-filename').innerText = `{json.dumps(ds['filename'])}`;\",\n",
        "            f\"document.getElementById('cc-dl-progress-bar-fill').style.width = '{ds['progress']}%';\",\n",
        "            f\"document.getElementById('cc-dl-progress-text').innerText = `{ds['progress']}% at {ds.get('speed', 'N/A')}`;\",\n",
        "        ])\n",
        "    display(Javascript(\" \".join(js_commands)))\n",
        "\n",
        "def render_initial_html():\n",
        "    \"\"\"Renders the main HTML and CSS for the UI. This is called only once.\"\"\"\n",
        "    html = f\"\"\"\n",
        "    <style>\n",
        "        /* Import a modern, clean font */\n",
        "        @import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap');\n",
        "\n",
        "        /* --- CSS Variables for \"Neomorphic Dark\" Theme --- */\n",
        "        :root {{\n",
        "            --bg-panel: #1A1C23;\n",
        "            --bg-card: #242731;\n",
        "            --bg-card-hover: #2B2E3A;\n",
        "            --border-color: rgba(255, 255, 255, 0.1);\n",
        "            --shadow-color-deep: rgba(0, 0, 0, 0.4);\n",
        "            --shadow-color-light: rgba(0, 0, 0, 0.2);\n",
        "            --text-primary: #EAEBF0;\n",
        "            --text-secondary: #A0A3B1;\n",
        "            --text-tertiary: #6B6F80;\n",
        "            --accent-primary: #3B82F6;\n",
        "            --accent-secondary: #8B5CF6;\n",
        "            --status-success: #22C55E;\n",
        "            --status-warning: #F59E0B;\n",
        "            --status-error: #EF4444;\n",
        "            --font-main: 'Inter', sans-serif;\n",
        "        }}\n",
        "\n",
        "        /* --- Main Layout & Structure --- */\n",
        "        .cc-body-wrapper {{\n",
        "            font-family: var(--font-main);\n",
        "            background: transparent; /* KEY CHANGE: Transparent background */\n",
        "            padding: 10px 0;\n",
        "            margin: 10px 0; /* Ensures it does not cause horizontal scroll */\n",
        "        }}\n",
        "        .cc-container {{\n",
        "            display: flex;\n",
        "            flex-direction: column;\n",
        "            gap: 24px;\n",
        "            max-width: 1200px;\n",
        "            margin: auto;\n",
        "        }}\n",
        "        .cc-panel {{\n",
        "            background: var(--bg-panel);\n",
        "            border-radius: 16px;\n",
        "            padding: clamp(16px, 3vw, 24px); /* Dynamic padding */\n",
        "            border: 1px solid var(--border-color);\n",
        "            box-shadow: inset 0 1px 1px rgba(255, 255, 255, 0.05), 0 8px 32px var(--shadow-color-deep);\n",
        "            display: flex;\n",
        "            flex-direction: column;\n",
        "            gap: 20px;\n",
        "            transition: all 0.3s ease;\n",
        "        }}\n",
        "\n",
        "        /* --- Header --- */\n",
        "        .cc-header {{\n",
        "            display: flex; align-items: center; gap: 14px;\n",
        "            font-size: clamp(20px, 4vw, 24px); /* Responsive font size */\n",
        "            font-weight: 600;\n",
        "            padding-bottom: 16px; border-bottom: 1px solid var(--border-color);\n",
        "            color: var(--text-primary);\n",
        "        }}\n",
        "        .cc-header img {{\n",
        "            width: 36px; height: 36px;\n",
        "            filter: drop-shadow(0 0 8px var(--accent-primary));\n",
        "        }}\n",
        "\n",
        "        /* --- Status Section --- */\n",
        "        .cc-status-section {{\n",
        "            text-align: center; padding: 20px; border-radius: 12px;\n",
        "            background: var(--bg-card); border: 1px solid var(--border-color);\n",
        "            transition: border-color 0.5s ease, box-shadow 0.5s ease;\n",
        "            box-shadow: inset 0 2px 4px rgba(0,0,0,0.3), 0 4px 15px var(--shadow-color-light);\n",
        "        }}\n",
        "        body.system-ready .cc-status-section {{\n",
        "            border-color: var(--status-success);\n",
        "            box-shadow: inset 0 2px 4px rgba(0,0,0,0.3), 0 0 25px rgba(34, 197, 94, 0.3);\n",
        "        }}\n",
        "        .cc-status-text-container {{ display: flex; align-items: center; justify-content: center; gap: 12px; font-size: 18px; font-weight: 500; min-height: 28px; color: var(--text-secondary); }}\n",
        "        body.system-ready #cc-status-text {{ color: var(--status-success); font-weight: 600; }}\n",
        "\n",
        "        #cc-status-loader {{ width: 22px; height: 22px; }}\n",
        "        .arc-spinner {{ width: 100%; height: 100%; animation: arc-rotate 2s linear infinite; }}\n",
        "        .arc-spinner-path {{ stroke: var(--accent-primary); stroke-linecap: round; animation: arc-dash 1.5s ease-in-out infinite; }}\n",
        "        #cc-status-icon-ready {{ display: none; color: var(--status-success); }}\n",
        "\n",
        "        .cc-main-progress-bar {{ background-color: rgba(0,0,0,0.3); height: 10px; border-radius: 5px; margin-top: 16px; overflow: hidden; position: relative; box-shadow: inset 0 2px 4px var(--shadow-color-light); }}\n",
        "        .cc-main-progress-bar-fill {{ background: linear-gradient(90deg, var(--accent-secondary), var(--accent-primary)); height: 100%; border-radius: 5px; transition: width 0.6s cubic-bezier(0.65, 0, 0.35, 1); position: relative; }}\n",
        "        #cc-main-progress-bar-shine {{ position: absolute; top: 0; height: 100%; width: 20%; background: linear-gradient(90deg, transparent, rgba(255, 255, 255, 0.2), transparent); transition: left 0.6s cubic-bezier(0.65, 0, 0.35, 1); filter: blur(2px); opacity: 0.7; animation: progress-sheen 1.5s infinite; }}\n",
        "\n",
        "        /* --- URL & Vitals --- */\n",
        "        .cc-url-section, .cc-vitals-grid {{ display: grid; grid-template-columns: repeat(auto-fit, minmax(200px, 1fr)); gap: 16px; }}\n",
        "        .cc-button, .cc-vital-card {{\n",
        "            background: var(--bg-card); border-radius: 12px; padding: 16px;\n",
        "            border: 1px solid var(--border-color); transition: all 0.25s ease;\n",
        "            box-shadow: inset 0 1px 1px rgba(255,255,255,0.03), 0 4px 12px var(--shadow-color-light);\n",
        "        }}\n",
        "        .cc-button:hover, .cc-vital-card:hover {{ transform: translateY(-3px); border-color: var(--border-color); background: var(--bg-card-hover); box-shadow: inset 0 1px 1px rgba(255,255,255,0.03), 0 6px 20px var(--shadow-color-deep); }}\n",
        "\n",
        "        .cc-button {{ text-decoration: none; font-weight: 500; font-size: 15px; color: var(--text-primary); display: flex; align-items: center; justify-content: center; gap: 10px; }}\n",
        "        .cc-button.disabled {{ color: var(--text-tertiary); background: transparent; cursor: not-allowed; box-shadow: inset 0 2px 4px var(--shadow-color-light); }}\n",
        "\n",
        "        .cc-card-header {{ display: flex; align-items: center; justify-content: space-between; gap: 8px; font-weight: 500; font-size: 13px; text-transform: uppercase; letter-spacing: 0.8px; color: var(--text-secondary); margin-bottom: 12px; }}\n",
        "        .cc-card-header > span {{ display: flex; align-items: center; gap: 8px; }}\n",
        "        .cc-progress-bar-bg {{ background-color: rgba(0,0,0,0.3); border-radius: 4px; height: 8px; overflow: hidden; }}\n",
        "        .cc-progress-bar-fill {{ height: 100%; border-radius: 4px; transition: width 0.4s ease; }}\n",
        "        .cc-label {{ display:flex; justify-content: space-between; font-size: 13px; color: var(--text-secondary); }}\n",
        "        #cc-download-monitor {{ grid-column: 1 / -1; display: none; }}\n",
        "\n",
        "        /* --- Live Log Panel --- */\n",
        "        .cc-log-panel {{ flex-grow: 1; display: flex; flex-direction: column; min-height: 400px; }}\n",
        "        .cc-log-panel-header {{ display: flex; justify-content: space-between; align-items: center; flex-wrap: wrap; gap: 16px; padding-bottom: 16px; border-bottom: 1px solid var(--border-color); flex-shrink: 0; }}\n",
        "        .cc-log-title {{ display: flex; align-items: center; gap: 10px; font-size: 20px; font-weight: 600; }}\n",
        "        .cc-log-filters {{ display: flex; gap: 16px; align-items: center; flex-wrap: wrap; }}\n",
        "        .cc-log-filter-label {{ display: flex; align-items: center; gap: 6px; font-size: 13px; cursor: pointer; color: var(--text-secondary); transition: color 0.2s; }}\n",
        "        .cc-log-filter-label:hover {{ color: var(--text-primary); }}\n",
        "        .cc-log-filter-label input {{ accent-color: var(--accent-primary); }}\n",
        "        #cc-resume-scroll-btn {{ background: var(--accent-primary); color: white; border: none; border-radius: 20px; padding: 4px 12px; font-size: 12px; font-weight: 600; cursor: pointer; display: none; transition: opacity 0.3s; }}\n",
        "\n",
        "        .cc-log-entries-wrapper {{ flex-grow: 1; overflow: hidden; position: relative; }}\n",
        "        .cc-log-entries {{ position: absolute; top: 0; left: 0; right: 0; bottom: 0; overflow-y: auto; padding-right: 10px; scrollbar-width: thin; scrollbar-color: var(--text-tertiary) transparent; }}\n",
        "        .cc-log-entries::-webkit-scrollbar {{ width: 8px; }}\n",
        "        .cc-log-entries::-webkit-scrollbar-track {{ background: rgba(0,0,0,0.2); border-radius: 4px; }}\n",
        "        .cc-log-entries::-webkit-scrollbar-thumb {{ background: var(--text-tertiary); border-radius: 4px; border: 2px solid transparent; background-clip: content-box; }}\n",
        "        .cc-log-entries::-webkit-scrollbar-thumb:hover {{ background: var(--text-secondary); }}\n",
        "\n",
        "        .cc-log-entry {{ display: flex; padding: 8px 0; border-bottom: 1px solid rgba(255, 255, 255, 0.05); opacity: 0; animation: fadeIn 0.5s ease forwards; }}\n",
        "        .cc-log-gutter {{ flex-shrink: 0; width: 4px; margin-right: 12px; border-radius: 2px; }}\n",
        "        .cc-log-content {{ display: flex; flex-direction: column; gap: 2px; }}\n",
        "        .cc-log-time {{ font-size: 11px; color: var(--text-tertiary); }}\n",
        "        .cc-log-message {{ font-size: 14px; color: var(--text-primary); word-break: break-word; }}\n",
        "\n",
        "        /* Log Gutter Colors */\n",
        "        .cc-log-info {{ background-color: var(--accent-primary); }}\n",
        "        .cc-log-success {{ background-color: var(--status-success); }}\n",
        "        .cc-log-warning {{ background-color: var(--status-warning); }}\n",
        "        .cc-log-error {{ background-color: var(--status-error); }}\n",
        "\n",
        "        /* --- Keyframe Animations --- */\n",
        "        @keyframes aurora-border {{ 0% {{ background-position: 0% 50%; }} 50% {{ background-position: 100% 50%; }} 100% {{ background-position: 0% 50%; }} }}\n",
        "        @keyframes arc-rotate {{ 100% {{ transform: rotate(360deg); }} }}\n",
        "        @keyframes arc-dash {{ 0% {{ stroke-dasharray: 1, 150; stroke-dashoffset: 0; }} 50% {{ stroke-dasharray: 90, 150; stroke-dashoffset: -35; }} 100% {{ stroke-dasharray: 90, 150; stroke-dashoffset: -124; }} }}\n",
        "        @keyframes fadeIn {{ to {{ opacity: 1; }} }}\n",
        "        @keyframes progress-sheen {{ 0% {{ transform: translateX(-50%) scaleX(0.1); opacity: 0; }} 50% {{ transform: translateX(0) scaleX(1); opacity: 0.7; }} 100% {{ transform: translateX(50%) scaleX(0.1); opacity: 0; }} }}\n",
        "\n",
        "        /* --- Responsive Design for Desktop & Tablets --- */\n",
        "        @media (min-width: 960px) {{\n",
        "            .cc-container {{ flex-direction: row; }}\n",
        "            .cc-panel.cc-left-panel {{ flex: 4; min-width: 400px; }}\n",
        "            .cc-panel.cc-log-panel {{ flex: 5; min-width: 500px; }}\n",
        "        }}\n",
        "    </style>\n",
        "    <div class=\"cc-body-wrapper\">\n",
        "    <div class=\"cc-container\">\n",
        "        <!-- Left Panel: Command & Status -->\n",
        "        <div class=\"cc-panel cc-left-panel\">\n",
        "            <div class=\"cc-header\">\n",
        "                <img src=\"https://cdn.jsdelivr.net/gh/homarr-labs/dashboard-icons/png/comfy-ui.png\" alt=\"ComfyUI Logo\">\n",
        "                <span>ComfyUI Command Center</span>\n",
        "            </div>\n",
        "            <div id=\"cc-status-section\" class=\"cc-status-section\">\n",
        "                <div id=\"cc-status-text-container\" class=\"cc-status-text-container\">\n",
        "                    <span id=\"cc-status-loader\"><svg class=\"arc-spinner\" viewBox=\"0 0 50 50\"><circle class=\"arc-spinner-path\" cx=\"25\" cy=\"25\" r=\"20\" fill=\"none\" stroke-width=\"4\"></circle></svg></span>\n",
        "                    <span id=\"cc-status-icon-ready\">{ICONS['ready']}</span>\n",
        "                    <span id=\"cc-status-text\">Initializing...</span>\n",
        "                </div>\n",
        "                <div class=\"cc-main-progress-bar\">\n",
        "                    <div id=\"cc-main-progress-bar-fill\" class=\"cc-main-progress-bar-fill\"></div>\n",
        "                    <div id=\"cc-main-progress-bar-shine\"></div>\n",
        "                </div>\n",
        "            </div>\n",
        "            <div class=\"cc-url-section\">\n",
        "                <a id=\"cc-local-url-button\" href=\"#\" target=\"_blank\" class=\"cc-button disabled\">{ICONS['link']} Launch Local UI</a>\n",
        "                <a id=\"cc-public-url-button\" href=\"#\" target=\"_blank\" class=\"cc-button disabled\">{ICONS['globe']} Open Public URL</a>\n",
        "            </div>\n",
        "            <div class=\"cc-vitals-grid\">\n",
        "                <div id=\"cc-download-monitor\" class=\"cc-vital-card\">\n",
        "                    <div class=\"cc-card-header\"><span>{ICONS['download']} DOWNLOADING</span></div>\n",
        "                    <div id=\"cc-dl-filename\" style=\"font-size: 13px; color: var(--text-secondary); margin-bottom: 8px;\"></div>\n",
        "                    <div class=\"cc-progress-bar-bg\"><div id=\"cc-dl-progress-bar-fill\" class=\"cc-progress-bar-fill\" style=\"background: var(--status-warning);\"></div></div>\n",
        "                    <div id=\"cc-dl-progress-text\" style=\"font-size: 12px; text-align: right; color: var(--text-tertiary); margin-top: 4px;\"></div>\n",
        "                </div>\n",
        "                <div class=\"cc-vital-card\">\n",
        "                    <div class=\"cc-card-header\"><span>{ICONS['gpu']} GPU</span><span id=\"cc-gpu-name\">N/A</span></div>\n",
        "                    <div class=\"cc-label\"><span>VRAM</span><span id=\"cc-vram-text\">0/0 GB</span></div>\n",
        "                    <div class=\"cc-progress-bar-bg\" style=\"margin: 4px 0;\"><div id=\"cc-vram-bar-fill\" class=\"cc-progress-bar-fill\" style=\"background: var(--accent-primary);\"></div></div>\n",
        "                    <div class=\"cc-label\" style=\"margin-top: 8px;\"><span>Util.</span><span id=\"cc-gpu-util-text\">0%</span></div>\n",
        "                    <div class=\"cc-progress-bar-bg\" style=\"margin-top: 4px;\"><div id=\"cc-gpu-util-bar-fill\" class=\"cc-progress-bar-fill\" style=\"background: var(--accent-secondary);\"></div></div>\n",
        "                </div>\n",
        "                <div class=\"cc-vital-card\">\n",
        "                    <div class=\"cc-card-header\"><span>{ICONS['cpu']} CPU & RAM</span></div>\n",
        "                    <div class=\"cc-label\"><span>RAM</span><span id=\"cc-ram-text\">0/0 GB</span></div>\n",
        "                    <div class=\"cc-progress-bar-bg\" style=\"margin: 4px 0;\"><div id=\"cc-ram-bar-fill\" class=\"cc-progress-bar-fill\" style=\"background: var(--accent-primary);\"></div></div>\n",
        "                    <div class=\"cc-label\" style=\"margin-top: 8px;\"><span>Usage</span><span id=\"cc-cpu-usage-text\">0%</span></div>\n",
        "                    <div class=\"cc-progress-bar-bg\" style=\"margin-top: 4px;\"><div id=\"cc-cpu-usage-bar-fill\" class=\"cc-progress-bar-fill\" style=\"background: var(--status-success);\"></div></div>\n",
        "                </div>\n",
        "                <div class=\"cc-vital-card\">\n",
        "                    <div class=\"cc-card-header\"><span>{ICONS['disk']} DISK</span><span>/content</span></div>\n",
        "                    <div class=\"cc-label\"><span>Used</span><span id=\"cc-disk-text\">0/0 GB</span></div>\n",
        "                    <div class=\"cc-progress-bar-bg\" style=\"margin-top: 4px;\"><div id=\"cc-disk-bar-fill\" class=\"cc-progress-bar-fill\" style=\"background: var(--status-warning);\"></div></div>\n",
        "                </div>\n",
        "                 <div class=\"cc-vital-card\">\n",
        "                    <div class=\"cc-card-header\"><span>{ICONS['timer']} TIMERS</span></div>\n",
        "                    <div style=\"font-size: 14px; display: flex; flex-direction: column; gap: 8px;\">\n",
        "                        <div class=\"cc-label\"><span>Setup Time:</span> <span id=\"cc-setup-time-value\" style='color: var(--text-primary); font-weight: 600;'>00:00:00</span></div>\n",
        "                        <div class=\"cc-label\"><span>UI Uptime:</span> <span id=\"cc-uptime-value\" style='color: var(--text-primary); font-weight: 600;'>Offline</span></div>\n",
        "                    </div>\n",
        "                </div>\n",
        "            </div>\n",
        "        </div>\n",
        "        <!-- Right Panel: Live Log -->\n",
        "        <div class=\"cc-panel cc-log-panel\">\n",
        "             <div class=\"cc-log-panel-header\">\n",
        "                <div class=\"cc-log-title\">{ICONS['log']} Live Event Log</div>\n",
        "                <div class=\"cc-log-filters\">\n",
        "                    <button id=\"cc-resume-scroll-btn\">▼ Resume</button>\n",
        "                    <label class=\"cc-log-filter-label\" for=\"log-filter-info\"><input type=\"checkbox\" id=\"log-filter-info\" checked onchange=\"updateLogFilter()\"> Info</label>\n",
        "                    <label class=\"cc-log-filter-label\" for=\"log-filter-success\"><input type=\"checkbox\" id=\"log-filter-success\" checked onchange=\"updateLogFilter()\"> Success</label>\n",
        "                    <label class=\"cc-log-filter-label\" for=\"log-filter-warning\"><input type=\"checkbox\" id=\"log-filter-warning\" checked onchange=\"updateLogFilter()\"> Warning</label>\n",
        "                    <label class=\"cc-log-filter-label\" for=\"log-filter-error\"><input type=\"checkbox\" id=\"log-filter-error\" checked onchange=\"updateLogFilter()\"> Error</label>\n",
        "                </div>\n",
        "            </div>\n",
        "            <div class=\"cc-log-entries-wrapper\">\n",
        "                <div class=\"cc-log-entries\" id=\"cc-log-entries-container\"></div>\n",
        "            </div>\n",
        "        </div>\n",
        "    </div>\n",
        "    </div>\n",
        "    <script>\n",
        "    function updateLogFilter() {{\n",
        "        const filters = {{\n",
        "            info: document.getElementById('log-filter-info').checked,\n",
        "            success: document.getElementById('log-filter-success').checked,\n",
        "            warning: document.getElementById('log-filter-warning').checked,\n",
        "            error: document.getElementById('log-filter-error').checked\n",
        "        }};\n",
        "        document.querySelectorAll('.cc-log-entry').forEach(entry => {{\n",
        "            entry.style.display = filters[entry.dataset.level] ? 'flex' : 'none';\n",
        "        }});\n",
        "    }}\n",
        "\n",
        "    (() => {{\n",
        "        const logContainer = document.getElementById('cc-log-entries-container');\n",
        "        if (!logContainer) return;\n",
        "        let userHasScrolled = false;\n",
        "        const resumeBtn = document.getElementById('cc-resume-scroll-btn');\n",
        "        logContainer.addEventListener('scroll', () => {{\n",
        "            const atBottom = logContainer.scrollHeight - logContainer.scrollTop - logContainer.clientHeight < 20;\n",
        "            if (!atBottom) {{\n",
        "                if (!userHasScrolled) {{ userHasScrolled = true; resumeBtn.style.display = 'inline-block'; }}\n",
        "            }} else {{\n",
        "                if (userHasScrolled) {{ userHasScrolled = false; resumeBtn.style.display = 'none'; }}\n",
        "            }}\n",
        "        }});\n",
        "        resumeBtn.addEventListener('click', () => {{\n",
        "            userHasScrolled = false;\n",
        "            logContainer.scrollTop = logContainer.scrollHeight;\n",
        "            resumeBtn.style.display = 'none';\n",
        "        }});\n",
        "    }})();\n",
        "    </script>\n",
        "    \"\"\"\n",
        "    display(HTML(html))\n",
        "\n",
        "def monitor_server_readiness():\n",
        "    \"\"\"Polls the ComfyUI server until it's ready to accept connections.\"\"\"\n",
        "    max_wait = 300\n",
        "    start_time = time.time()\n",
        "    while time.time() - start_time < max_wait:\n",
        "        try:\n",
        "            # [FIX] Changed to poll a more reliable endpoint that is available earlier\n",
        "            response = requests.get('http://127.0.0.1:8188/', timeout=1)\n",
        "            if response.status_code == 200:\n",
        "                setup_time_delta = datetime.now() - status_info['start_time']\n",
        "                update_status(progress=100, ready=True, local_url=\"http://127.0.0.1:8188\", server_start_time=datetime.now(), setup_time=str(timedelta(seconds=int(setup_time_delta.total_seconds()))).split('.')[0])\n",
        "                # [FIX] This message is now redundant because the log parser handles it.\n",
        "                # add_log_to_widget(\"ComfyUI is fully online and accessible!\", 'success')\n",
        "                return\n",
        "        except requests.exceptions.RequestException: pass\n",
        "        time.sleep(1)\n",
        "    add_log_to_widget(\"Server readiness check timed out. ComfyUI may still be loading in the background.\", 'error')\n",
        "    update_status(step=\"Startup Timeout\")\n",
        "\n",
        "def stream_and_parse_comfyui_output(process):\n",
        "    \"\"\"\n",
        "    Reads ComfyUI's output, prints EVERY line to the notebook's standard output,\n",
        "    and intelligently parses it to create a clean, human-readable summary in the UI log.\n",
        "    \"\"\"\n",
        "    # [FINAL POLISH] Enhanced parsing rules\n",
        "    version_regex = re.compile(r\"^\\s?\\*\\* ComfyUI Version: (v[\\d\\.-]+)\")\n",
        "    node_time_regex = re.compile(r\"^\\s*(\\d+\\.\\d+) seconds: .*?([^/\\\\_]+)$\")\n",
        "    missing_model_regex = re.compile(r\"Value not in list: (\\w+): '([^']*)'\")\n",
        "    dl_start_regex = re.compile(r\"\\[UniversalAssetDownloader\\] Starting download: (.*)\")\n",
        "    dl_complete_regex = re.compile(r\"\\[UniversalAssetDownloader\\] ✅ Download completed: (.*)\")\n",
        "    restart_regex = re.compile(r\"Restarting\\.\\.\\. \\[Legacy Mode\\]\")\n",
        "    db_error_regex = re.compile(r\"Failed to initialize database.*(sqlite3\\.OperationalError)\")\n",
        "\n",
        "    ignore_patterns = [\n",
        "        \"Unable to register cuFFT factory\",\n",
        "        \"Unable to register cuDNN factory\",\n",
        "        \"Unable to register cuBLAS factory\",\n",
        "        \"This TensorFlow binary is optimized\",\n",
        "        re.compile(r\"^FETCH ComfyRegistry Data\"),\n",
        "        re.compile(r\"^Added static route\"),\n",
        "        re.compile(r\"^Error saving metadata to\"),\n",
        "        \"Metadata collection hooks installed\",\n",
        "        \"Usage statistics tracker initialized\",\n",
        "        \"Cache files disabled for\",\n",
        "        \"Recipe cache initialized\",\n",
        "        re.compile(r\"^\\[Civicomfy.*\"),\n",
        "        re.compile(r\"^\\[Manager\\].*\"),\n",
        "        re.compile(r\"^\\[Crystools INFO\\]\"),\n",
        "        re.compile(r\"^Found (LoRA|checkpoint) roots\"),\n",
        "        re.compile(r\"^Added path mapping\"),\n",
        "        \"Saved folder paths to settings.json\",\n",
        "    ]\n",
        "\n",
        "    parsing_prestartup_times = False\n",
        "    parsing_import_times = False\n",
        "\n",
        "    for line in iter(process.stdout.readline, ''):\n",
        "        print(line, end='')\n",
        "        line_clean = line.strip().replace('\\\\', '/') # Normalize path separators\n",
        "        if not line_clean: continue\n",
        "\n",
        "        if any(p.search(line_clean) if hasattr(p, 'search') else p in line_clean for p in ignore_patterns):\n",
        "            continue\n",
        "\n",
        "        if (match := version_regex.search(line_clean)):\n",
        "            add_log_to_widget(f\"ComfyUI Version {match.group(1)} started.\", 'success')\n",
        "            continue\n",
        "        if (match := dl_start_regex.search(line_clean)):\n",
        "            add_log_to_widget(f\"Downloading: {os.path.basename(match.group(1))}\", 'info')\n",
        "            continue\n",
        "        if (match := dl_complete_regex.search(line_clean)):\n",
        "            add_log_to_widget(f\"Download complete: {match.group(1)}\", 'success')\n",
        "            continue\n",
        "        if (match := restart_regex.search(line_clean)):\n",
        "            add_log_to_widget(\"ComfyUI is restarting via Manager...\", 'warning')\n",
        "            continue\n",
        "        if (match := db_error_regex.search(line_clean)):\n",
        "            add_log_to_widget(\"A node failed to create its database file (common on GDrive), but should fall back gracefully.\", 'warning')\n",
        "            continue\n",
        "        if \"Failed to validate prompt\" in line_clean:\n",
        "            if (match := missing_model_regex.search(line)): # Use original line for this one\n",
        "                add_log_to_widget(f\"Workflow error: Missing {match.group(1).replace('_name','')} '{match.group(2)}'\", 'error')\n",
        "            else:\n",
        "                add_log_to_widget(\"Workflow validation failed. Check for missing models.\", 'error')\n",
        "            continue\n",
        "\n",
        "        if \"Prestartup times for custom nodes:\" in line_clean:\n",
        "            parsing_prestartup_times = True\n",
        "            add_log_to_widget(\"Analyzing custom node pre-startup times...\", 'info')\n",
        "            continue\n",
        "        if \"Import times for custom nodes:\" in line_clean:\n",
        "            parsing_import_times = True\n",
        "            add_log_to_widget(\"Analyzing custom node import times...\", 'info')\n",
        "            continue\n",
        "\n",
        "        if parsing_prestartup_times or parsing_import_times:\n",
        "            if (match := node_time_regex.search(line_clean)):\n",
        "                time_taken = float(match.group(1))\n",
        "                node_name = match.group(2).strip()\n",
        "                if time_taken >= 1.0:\n",
        "                    add_log_to_widget(f\"Slow node: '{node_name}' took {time_taken:.1f}s to load.\", 'warning')\n",
        "            else:\n",
        "                parsing_prestartup_times = False\n",
        "                parsing_import_times = False\n",
        "\n",
        "        if \"Total VRAM\" in line_clean:\n",
        "            add_log_to_widget(\"GPU and VRAM initialized.\", 'success')\n",
        "        elif \"To see the GUI go to:\" in line_clean:\n",
        "            add_log_to_widget(\"Server is now ready to accept connections.\", 'success')\n",
        "        elif \"Warning: Could not load\" in line_clean:\n",
        "             add_log_to_widget(line_clean.replace(\"Warning: \", \"\"), 'warning')\n",
        "\n",
        "# --- Real-Time Update Thread ---\n",
        "def start_ui_update_thread():\n",
        "    \"\"\"Starts a background thread to update the UI every second.\"\"\"\n",
        "    def ui_updater():\n",
        "        while True:\n",
        "            if comfyui_process and comfyui_process.poll() is not None: break\n",
        "            if status_info['ui_rendered']: generate_update_script()\n",
        "            time.sleep(1)\n",
        "\n",
        "    update_thread = threading.Thread(target=ui_updater, daemon=True)\n",
        "    update_thread.start()\n",
        "\n",
        "# --- Main Execution Flow ---\n",
        "if not status_info['ui_rendered']:\n",
        "    clear_output() # Clear previous output for a clean slate\n",
        "    render_initial_html()\n",
        "    status_info['ui_rendered'] = True\n",
        "\n",
        "comfyui_process = None\n",
        "start_ui_update_thread()\n",
        "\n",
        "# Start the setup sequence and update the UI accordingly\n",
        "update_status(step=\"Verifying Setup\", progress=10)\n",
        "add_log_to_widget(\"Analyzing user configuration...\", 'info')\n",
        "\n",
        "if 'SAVE_TO_GDRIVE' not in globals(): SAVE_TO_GDRIVE = False\n",
        "if 'GDRIVE_BASE' not in globals() or not GDRIVE_BASE: GDRIVE_BASE = \"/content/drive/MyDrive/ComfyUI\"\n",
        "if 'NGROK_AUTHTOKEN' not in globals(): NGROK_AUTHTOKEN = None\n",
        "add_log_to_widget(f\"Storage mode: {'Google Drive' if SAVE_TO_GDRIVE else 'Local Runtime'}\", 'success')\n",
        "time.sleep(0.5)\n",
        "\n",
        "update_status(step=\"Configuring File Paths\", progress=20)\n",
        "add_log_to_widget(f\"Verifying directory structure...\", 'info')\n",
        "try:\n",
        "    # Always create persistent folders in GDrive\n",
        "    for folder in ['output', 'input', 'temp', 'user', 'custom_nodes', 'models/clip_vision', 'models/mmaudio', 'models/vae_approx']: # Added mmaudio and vae_approx here\n",
        "        os.makedirs(os.path.join(GDRIVE_BASE, folder), exist_ok=True)\n",
        "    # Always point custom_nodes, clip_vision, mmaudio, and vae_approx to GDrive for persistence\n",
        "    yaml_content = {\n",
        "        \"gdrive_storage\": {\n",
        "            \"custom_nodes\": f\"{GDRIVE_BASE}/custom_nodes/\",\n",
        "            \"clip_vision\": f\"{GDRIVE_BASE}/models/clip_vision/\",\n",
        "            \"mmaudio\": f\"{GDRIVE_BASE}/models/mmaudio/\", # Added mmaudio here\n",
        "            \"vae_approx\": f\"{GDRIVE_BASE}/models/vae_approx/\" # Added vae_approx here\n",
        "        }\n",
        "    }\n",
        "    with open(\"/content/ComfyUI/extra_model_paths.yaml\", 'w') as f:\n",
        "        yaml.dump(yaml_content, f)\n",
        "    add_log_to_widget(\"Directory structure and paths configured.\", 'success')\n",
        "except Exception as e:\n",
        "    add_log_to_widget(f\"Error during path setup: {e}\", 'error')\n",
        "    raise e\n",
        "time.sleep(0.5)\n",
        "\n",
        "# --- Create Symlinks for Persistent Model Downloads ---\n",
        "update_status(step=\"Linking Model Directories\", progress=35)\n",
        "if SAVE_TO_GDRIVE:\n",
        "    add_log_to_widget(\"Linking model folders to Google Drive for persistence...\", 'info')\n",
        "    model_directories = [\n",
        "        'checkpoints', 'loras', 'controlnet', 'vae', 'upscale_models',\n",
        "        'clip', 'unet', 'embeddings', 'diffusers', 'clip_vision', 'mmaudio', 'vae_approx' # Added mmaudio and vae_approx here\n",
        "    ]\n",
        "    base_comfyui_models_path = '/content/ComfyUI/models'\n",
        "    base_gdrive_models_path = os.path.join(GDRIVE_BASE, 'models')\n",
        "\n",
        "    for model_dir in model_directories:\n",
        "        local_path = os.path.join(base_comfyui_models_path, model_dir)\n",
        "        gdrive_path = os.path.join(base_gdrive_models_path, model_dir)\n",
        "        try:\n",
        "            os.makedirs(gdrive_path, exist_ok=True)\n",
        "            if os.path.exists(local_path) and not os.path.islink(local_path):\n",
        "                shutil.rmtree(local_path)\n",
        "            if not os.path.exists(local_path):\n",
        "                os.symlink(gdrive_path, local_path)\n",
        "                add_log_to_widget(f\"Linked {model_dir} to Google Drive.\", 'success')\n",
        "            else:\n",
        "                 add_log_to_widget(f\"Symlink for {model_dir} already exists.\", 'info')\n",
        "        except Exception as e:\n",
        "            add_log_to_widget(f\"Failed to link /models/{model_dir}: {e}\", 'error')\n",
        "else:\n",
        "    add_log_to_widget(\"GDrive storage is OFF. Skipping model directory linking.\", 'info')\n",
        "time.sleep(0.5)\n",
        "# -----------------------------------------------------------\n",
        "\n",
        "update_status(step=\"Setting Up Public Tunnel\", progress=50)\n",
        "public_url = \"Not Configured\"\n",
        "if NGROK_AUTHTOKEN and NGROK_AUTHTOKEN.strip():\n",
        "    # --- Robust Ngrok Startup with Enhanced Logging ---\n",
        "    add_log_to_widget(\"Cleaning up old ngrok processes...\", 'info')\n",
        "    for proc in psutil.process_iter(['pid', 'name']):\n",
        "        if 'ngrok' in proc.info['name']:\n",
        "            pid = proc.info['pid']\n",
        "            try:\n",
        "                p = psutil.Process(pid)\n",
        "                p.terminate()\n",
        "                try:\n",
        "                    p.wait(timeout=2)\n",
        "                    add_log_to_widget(f\"Terminated stale ngrok process (PID: {pid}).\", 'info')\n",
        "                except psutil.TimeoutExpired:\n",
        "                    add_log_to_widget(f\"Polite shutdown failed for ngrok (PID: {pid}), escalating...\", 'warning')\n",
        "                    p.kill()\n",
        "                    p.wait(timeout=2)\n",
        "                    add_log_to_widget(f\"Forcefully killed stale ngrok process (PID: {pid}).\", 'success')\n",
        "            except psutil.NoSuchProcess:\n",
        "                add_log_to_widget(f\"Stale ngrok process (PID: {pid}) vanished before cleanup.\", 'info')\n",
        "                pass # Process already gone, which is fine\n",
        "\n",
        "    add_log_to_widget(\"Initializing Ngrok for public access...\", 'info')\n",
        "    ngrok_process = subprocess.Popen(['/content/ngrok', 'http', '8188', '--log=stdout'], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
        "\n",
        "    retries = 10\n",
        "    last_error = None\n",
        "    for i in range(retries):\n",
        "        try:\n",
        "            time.sleep(2)\n",
        "            response = requests.get('http://127.0.0.1:4040/api/tunnels', timeout=5)\n",
        "            response.raise_for_status()\n",
        "            tunnels = response.json().get('tunnels', [])\n",
        "            if tunnels:\n",
        "                public_url = tunnels[0]['public_url']\n",
        "                add_log_to_widget(f\"Ngrok tunnel is live!\", 'success')\n",
        "                break\n",
        "        except Exception as e:\n",
        "            last_error = str(e)\n",
        "    else:\n",
        "        public_url = \"Error\"\n",
        "        add_log_to_widget(f\"Ngrok setup failed after {retries} retries. Error: {last_error}\", 'error')\n",
        "    # ------------------------------------\n",
        "else:\n",
        "    add_log_to_widget(\"Ngrok token not provided, skipping public URL.\", 'warning')\n",
        "update_status(public_url=public_url)\n",
        "time.sleep(0.5)\n",
        "\n",
        "update_status(step=\"Launching ComfyUI Server\", progress=75)\n",
        "os.chdir('/content/ComfyUI')\n",
        "add_log_to_widget(\"Starting main server process...\", 'info')\n",
        "readiness_thread = threading.Thread(target=monitor_server_readiness, daemon=True)\n",
        "readiness_thread.start()\n",
        "\n",
        "update_status(step=\"Initializing Server...\", progress=90)\n",
        "# Define launch arguments. These paths ensure outputs, inputs, etc., are saved to GDrive.\n",
        "# The model paths are now handled by the symlinks when SAVE_TO_GDRIVE is on.\n",
        "launch_args = ['python', 'main.py', '--listen', '0.0.0.0', '--port', '8188', '--cuda-device', '0',\n",
        "               '--output-directory', f\"{GDRIVE_BASE}/output\", '--input-directory', f\"{GDRIVE_BASE}/input\",\n",
        "               '--temp-directory', f\"{GDRIVE_BASE}/temp\", '--user-dir', f\"{GDRIVE_BASE}/user\"]\n",
        "comfyui_process = subprocess.Popen(launch_args, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True, encoding='utf-8', bufsize=1)\n",
        "\n",
        "output_stream_thread = threading.Thread(target=stream_and_parse_comfyui_output, args=(comfyui_process,), daemon=True)\n",
        "output_stream_thread.start()\n",
        "\n",
        "comfyui_process.wait()\n",
        "add_log_to_widget(\"ComfyUI process has terminated.\", 'error')\n",
        "update_status(step=\"Process Ended\", ready=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6390ee2"
      },
      "source": [
        "---\n",
        "\n",
        "## ✅ All Done!\n",
        "\n",
        "You have successfully set up and launched ComfyUI on Google Colab. If the Ngrok tunnel was successfully established, you can access the ComfyUI web interface using the public URL printed above.\n",
        "\n",
        "Happy generating! ✨"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3da043c2"
      },
      "source": [
        "* * *\n",
        "\n",
        "## 📥 Download and Install Workflows\n",
        "\n",
        "You can enhance your ComfyUI experience by downloading and using custom workflows. Workflows are saved as JSON files and define the arrangement of nodes and settings for a specific task.\n",
        "\n",
        "Here's how to download and use a workflow:\n",
        "\n",
        "1.  **Click the link below** to open the workflow JSON file in a new tab:\n",
        "\n",
        "    🔗 [Example Workflow with SDXL and Lora](https://gist.github.com/thaakeno/2b229b4b5de4fb3809dc6db00ae27ece)\n",
        "\n",
        "2.  **Here is another workflow for Flux 1. Kontext with GGUF:**\n",
        "\n",
        "    🔗 [Flux 1. Kontext workflow with GGUF](https://www.patreon.com/file?h=132806426&m=491518368)\n",
        "\n",
        "\n",
        "3.  **Here is a workflow for Flux 1. Kontext with GGUF with 2 Images Stitching:**\n",
        "\n",
        "    🔗 [Flux Kontext 1 GGUF with Image Stich\n",
        "Workflow](https://gist.github.com/thaakeno/fc4d09069501bff482921db1cecc1018)\n",
        "\n",
        "Here's how to download and use the WAN 2.2 T2V and I2V workflow (scroll down for I2V):\n",
        "\n",
        "4. **Click the link below** to open the workflow JSON file in a new tab:\n",
        "\n",
        "   🔗 [WAN 2.2 T2V and I2V Workflow](https://gist.github.com/thaakeno/7960b2a435d8bcb05c4bd9e47eeb4dea)\n",
        "\n",
        "\n",
        "5.  **Save the file:** Once the page loads, right-click on the raw text and select \"Save As...\" or \"Save page as...\". Save the file with a `.json` extension (e.g., `my_workflow.json`).\n",
        "\n",
        "6.  **Load the workflow in ComfyUI:**\n",
        "    *   Open the ComfyUI web interface (using the Ngrok URL from the previous cell).\n",
        "    *   Click the \"Load\" button in the ComfyUI interface.\n",
        "    *   Select the `.json` file you just downloaded.\n",
        "\n",
        "The workflow will be loaded into your ComfyUI graph, ready for you to use!\n",
        "\n",
        "* * *"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "940b79d4"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
